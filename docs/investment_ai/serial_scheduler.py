# ì§ë ¬ ì¹´ìš´íŒ… ê¸°ë°˜ ìŠ¤ì¼€ì¤„ëŸ¬ (ë¶„ì„ê¸° í˜¸ì¶œ + MongoDB ì €ì¥)

import asyncio
import logging
from datetime import datetime, timezone, timedelta
from typing import Dict, Optional, List, Tuple
from dataclasses import dataclass
from pymongo import MongoClient

logger = logging.getLogger("serial_scheduler")

@dataclass
class SerialTask:
    """ì§ë ¬ ì‘ì—… ì •ì˜"""
    name: str
    func: callable
    interval_cycles: int  # Në²ˆì˜ ë©”ì¸ ì‚¬ì´í´ë§ˆë‹¤ ì‹¤í–‰
    stage: str  # 'position', 'analysis', 'chart', 'technical', 'final'
    last_result: any = None
    cycle_counter: int = 0
    error_count: int = 0
    max_errors: int = 5
    is_running: bool = False
    dependencies: List[str] = None  # ì˜ì¡´ì„± ì‘ì—…ë“¤
    cache_duration_minutes: int = 10080  # ê¸°ë³¸ 7ì¼ ìºì‹œ (10080ë¶„)

class SerialDataScheduler:
    """ì§ë ¬ ì¹´ìš´íŒ… ê¸°ë°˜ ìŠ¤ì¼€ì¤„ëŸ¬ - ë¶„ì„ê¸° í˜¸ì¶œ + MongoDB ì €ì¥"""
    
    def __init__(self, main_cycle_minutes: int = 60):  # 15ë¶„ â†’ 60ë¶„ìœ¼ë¡œ ë³€ê²½
        self.main_cycle_minutes = main_cycle_minutes
        self.tasks: Dict[str, SerialTask] = {}
        self.global_cycle_count = 0
        
        # MongoDB ì—°ê²° ì„¤ì •
        self._setup_mongodb()
        
        # ì‹¤í–‰ ë‹¨ê³„ ìˆœì„œ ì •ì˜ (ë°ì´í„° ì˜ì¡´ì„±ì— ë”°ë¼)
        self.execution_stages = [
            'position',      # 1ë‹¨ê³„: í¬ì§€ì…˜ ë°ì´í„° (ì‹¤ì‹œê°„)
            'analysis',      # 2ë‹¨ê³„: ì°¨íŠ¸ ì™¸ ë¶„ì„ë“¤ (ê°ì ë°ì´í„° ìˆ˜ì§‘ í¬í•¨)
            'chart',         # 3ë‹¨ê³„: 60ë¶„ ìº”ë“¤ ì°¨íŠ¸ ì—…ë°ì´íŠ¸  # ì£¼ì„ ìˆ˜ì •
            'technical',     # 4ë‹¨ê³„: ê¸°ìˆ ì  ë¶„ì„ (ì°¨íŠ¸ ë°ì´í„° ì˜ì¡´)
            'final'          # 5ë‹¨ê³„: ìµœì¢… ê²°ì •
        ]
        
        # ì‘ì—…ë“¤ ë“±ë¡
        self._register_tasks()
        
        logger.info(f"ì§ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ (ë©”ì¸ ì‚¬ì´í´: {main_cycle_minutes}ë¶„) - MongoDB ì €ì¥ ê¸°ëŠ¥ í¬í•¨")

    def _setup_mongodb(self):
        """MongoDB ì—°ê²° ë° ìºì‹œ ì»¬ë ‰ì…˜ ì„¤ì •"""
        try:
            self.mongo_client = MongoClient("mongodb://mongodb:27017")
            self.database = self.mongo_client["bitcoin"]
            self.cache_collection = self.database["data_cache"]
            
            # ë§Œë£Œ ì‹œê°„ì„ ìœ„í•œ TTL ì¸ë±ìŠ¤ ìƒì„±
            try:
                self.cache_collection.create_index("expire_at", expireAfterSeconds=0)
                logger.info("ë°ì´í„° ìºì‹œ ì»¬ë ‰ì…˜ TTL ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
            except Exception as e:
                logger.debug(f"TTL ì¸ë±ìŠ¤ ìƒì„± ì˜¤ë¥˜ (ì´ë¯¸ ì¡´ì¬í•  ìˆ˜ ìˆìŒ): {e}")
                
            logger.info("MongoDB ë°ì´í„° ìºì‹œ ì—°ê²° ì™„ë£Œ")
        except Exception as e:
            logger.error(f"MongoDB ì—°ê²° ì‹¤íŒ¨: {e}")
            self.mongo_client = None
            self.database = None
            self.cache_collection = None
    
    def _register_tasks(self):
        """ì‘ì—…ë“¤ ë“±ë¡ - ë¶„ì„ê¸° í•¨ìˆ˜ í˜¸ì¶œë§Œ"""
        
        # ğŸ”§ ìˆ˜ì •: ëª¨ë“  ìºì‹œë¥¼ 7ì¼(10080ë¶„)ë¡œ ì„¤ì •
        cache_duration_7days = 10080  # 7ì¼ = 7 * 24 * 60 = 10080ë¶„
        
        # 1ë‹¨ê³„: í¬ì§€ì…˜ ë°ì´í„° (ë§¤ë²ˆ ì‹¤í–‰, ìºì‹œ ì—†ìŒ)
        self.register_task("position_data", self._get_position_data, 1, "position", cache_duration_minutes=0)
        
        # 2ë‹¨ê³„: ì°¨íŠ¸ ì™¸ AI ë¶„ì„ë“¤ (ê° ë¶„ì„ê¸°ê°€ ë°ì´í„° ìˆ˜ì§‘ í¬í•¨) - ì‹¤í–‰ ì£¼ê¸° ìˆ˜ì •
        self.register_task("ai_sentiment_analysis", self._ai_sentiment_analysis, 1, "analysis", cache_duration_minutes=cache_duration_7days)  # 2â†’1ë¡œ ë³€ê²½: 1ì‹œê°„ë§ˆë‹¤
        self.register_task("ai_macro_analysis", self._ai_macro_analysis, 6, "analysis", cache_duration_minutes=cache_duration_7days)  # 24â†’6ìœ¼ë¡œ ë³€ê²½: 6ì‹œê°„ë§ˆë‹¤
        self.register_task("ai_onchain_analysis", self._ai_onchain_analysis, 1, "analysis", cache_duration_minutes=cache_duration_7days)  # 4â†’1ë¡œ ë³€ê²½: 1ì‹œê°„ë§ˆë‹¤
        self.register_task("ai_institutional_analysis", self._ai_institutional_analysis, 2, "analysis", cache_duration_minutes=cache_duration_7days)  # 8â†’2ë¡œ ë³€ê²½: 2ì‹œê°„ë§ˆë‹¤
        
        # 3ë‹¨ê³„: ì°¨íŠ¸ ë°ì´í„° ì—…ë°ì´íŠ¸ (ë§¤ë²ˆ ì‹¤í–‰)
        self.register_task("chart_update", self._update_chart_data, 1, "chart", cache_duration_minutes=cache_duration_7days)
        
        # 4ë‹¨ê³„: ê¸°ìˆ ì  ë¶„ì„ (ì°¨íŠ¸ ë°ì´í„° ì˜ì¡´)
        self.register_task("ai_technical_analysis", self._ai_technical_analysis, 1, "technical",
                        dependencies=["chart_update"], cache_duration_minutes=cache_duration_7days)
        
        # 5ë‹¨ê³„: ìµœì¢… ê²°ì • (ëª¨ë“  ë¶„ì„ ì˜ì¡´)
        self.register_task("final_decision", self._final_decision, 1, "final",
                        dependencies=["ai_technical_analysis", "ai_sentiment_analysis", 
                                    "ai_macro_analysis", "ai_onchain_analysis", 
                                    "ai_institutional_analysis", "position_data"],
                        cache_duration_minutes=cache_duration_7days)
        
        logger.info(f"ì‘ì—… ë“±ë¡ ì™„ë£Œ: {len(self.tasks)}ê°œ (ëª¨ë“  ìºì‹œ 7ì¼ ìœ ì§€)")
        
        # ë‹¨ê³„ë³„ ì‘ì—… ìˆ˜ ë¡œê¹…
        for stage in self.execution_stages:
            stage_tasks = [name for name, task in self.tasks.items() if task.stage == stage]
            logger.info(f"  {stage}: {len(stage_tasks)}ê°œ ì‘ì—…")
    
    def register_task(self, name: str, func: callable, interval_cycles: int, stage: str, 
                     dependencies: List[str] = None, cache_duration_minutes: int = 60):
        """ì‘ì—… ë“±ë¡"""
        self.tasks[name] = SerialTask(
            name=name,
            func=func,
            interval_cycles=interval_cycles,
            stage=stage,
            dependencies=dependencies or [],
            cache_duration_minutes=cache_duration_minutes
        )
        interval_minutes = interval_cycles * self.main_cycle_minutes
        logger.debug(f"ì‘ì—… ë“±ë¡: {name} [{stage}] (ì£¼ê¸°: {interval_minutes}ë¶„, ìºì‹œ: {cache_duration_minutes}ë¶„)")
    
    def should_run_task(self, task: SerialTask, force_all_analysis: bool = False) -> Tuple[bool, str]:
        """ì‘ì—… ì‹¤í–‰ ì—¬ë¶€ íŒë‹¨ - ì¹´ìš´íŒ… + ì˜ì¡´ì„± ì²´í¬ + ì´ˆê¸° ê°•ì œ ì‹¤í–‰"""
        if task.is_running:
            return False, "already_running"
        
        if task.error_count >= task.max_errors:
            return False, f"disabled({task.error_count} errors)"
        
        # ğŸ”§ ì´ˆê¸° ì‹¤í–‰ì‹œ ëª¨ë“  ë¶„ì„ ë° final_decision ê°•ì œ ì‹¤í–‰
        if force_all_analysis and (task.name.startswith('ai_') or task.name == 'final_decision'):
            logger.info(f"ğŸ”¥ ì´ˆê¸° ì‹¤í–‰: {task.name} ê°•ì œ ì‹¤í–‰")
            return True, "forced_initial_execution"
        
        # ì¹´ìš´íŒ… ê¸°ë°˜ ì‹¤í–‰ ì£¼ê¸° ì²´í¬
        if (self.global_cycle_count % task.interval_cycles) != 0:
            cycles_left = task.interval_cycles - (self.global_cycle_count % task.interval_cycles)
            return False, f"wait_{cycles_left}_cycles"
        
        # ì˜ì¡´ì„± ì²´í¬
        missing_deps = []
        for dep_name in task.dependencies:
            if dep_name not in self.tasks:
                missing_deps.append(f"{dep_name}(not_registered)")
                continue
                
            dep_task = self.tasks[dep_name]
            if dep_task.last_result is None:
                missing_deps.append(f"{dep_name}(no_result)")
            elif dep_task.error_count >= dep_task.max_errors:
                missing_deps.append(f"{dep_name}(disabled)")
        
        if missing_deps:
            return False, f"missing_deps:{','.join(missing_deps)}"
        
        return True, "ready"

    def get_cached_data(self, task_name: str) -> Optional[any]:
        """MongoDBì—ì„œ ìºì‹œëœ ë°ì´í„° ë°˜í™˜ - ë²„ê·¸ ìˆ˜ì •"""
        if task_name not in self.tasks:
            return None
        
        task = self.tasks[task_name]
        
        # ìºì‹œ ì‚¬ìš© ì•ˆí•˜ëŠ” ê²½ìš°
        if task.cache_duration_minutes == 0 or self.cache_collection is None:
            return None
        
        try:
            # âœ… ìˆ˜ì •: aggregateë¥¼ ì‚¬ìš©í•´ì„œ ê°€ì¥ í™•ì‹¤í•˜ê²Œ ìµœì‹  ë¬¸ì„œ í•˜ë‚˜ë§Œ ê°€ì ¸ì˜¤ê¸°
            pipeline = [
                {
                    "$match": {
                        "task_name": task_name,
                        "expire_at": {"$gt": datetime.now(timezone.utc)}
                    }
                },
                {"$sort": {"created_at": -1}},  # ìµœì‹ ìˆœ ì •ë ¬
                {"$limit": 1}                   # í•˜ë‚˜ë§Œ ê°€ì ¸ì˜¤ê¸°
            ]
            
            result = list(self.cache_collection.aggregate(pipeline))
            
            if result:
                cache_doc = result[0]
                logger.debug(f"MongoDB ìºì‹œëœ ë°ì´í„° ì‚¬ìš©: {task_name} (created: {cache_doc.get('created_at')})")
                return cache_doc.get("data")
            else:
                logger.debug(f"MongoDB ìºì‹œ ë°ì´í„° ì—†ìŒ: {task_name}")
                return None
            
        except Exception as e:
            logger.error(f"ìºì‹œ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜ ({task_name}): {e}")
            return None

    def _update_cache(self, task: SerialTask, data: any):
        """MongoDBì— ìºì‹œ ë°ì´í„° ì €ì¥ - ë””ë²„ê¹… ë¡œê·¸ ê°•í™”"""
        if task.cache_duration_minutes == 0:
            logger.debug(f"ìºì‹œ ë¹„í™œì„±í™”: {task.name} (cache_duration=0)")
            return
            
        if self.cache_collection is None:
            logger.error(f"MongoDB ì—°ê²° ì—†ìŒ: {task.name} ì €ì¥ ì‹¤íŒ¨")
            return
        
        try:
            expire_at = datetime.now(timezone.utc) + timedelta(minutes=task.cache_duration_minutes)
            
            # ì €ì¥í•  ë°ì´í„° í¬ê¸° í™•ì¸
            data_size = len(str(data)) if data else 0
            logger.info(f"MongoDB ì €ì¥ ì‹œë„: {task.name} (ë°ì´í„° í¬ê¸°: {data_size}bytes, ë§Œë£Œ: {task.cache_duration_minutes}ë¶„)")
            
            # ìƒˆ ë¬¸ì„œë¡œ ì‚½ì… (ë®ì–´ì“°ì§€ ì•ŠìŒ)
            result = self.cache_collection.insert_one({
                "task_name": task.name,
                "data": data,
                "created_at": datetime.now(timezone.utc),
                "expire_at": expire_at
            })
            
            # ì €ì¥ ê²°ê³¼ í™•ì¸
            if result.inserted_id:
                logger.info(f"âœ… MongoDB ìƒˆ ë¬¸ì„œ ìƒì„±: {task.name} (ID: {result.inserted_id})")
            else:
                logger.warning(f"âš ï¸ MongoDB ì €ì¥ ì‹¤íŒ¨: {task.name}")
                
        except Exception as e:
            logger.error(f"âŒ MongoDB ì €ì¥ ì‹¤íŒ¨: {task.name} - {type(e).__name__}: {e}")
            # ì¶”ê°€ ë””ë²„ê¹… ì •ë³´
            logger.error(f"   ë°ì´í„° íƒ€ì…: {type(data)}, MongoDB ì—°ê²°: {self.cache_collection is not None}")
            if hasattr(e, 'details'):
                logger.error(f"   ì˜¤ë¥˜ ìƒì„¸: {e.details}")

    
    async def run_task(self, task: SerialTask, stage_name: str, task_index: int, total_tasks: int) -> bool:
        """ê°œë³„ ì‘ì—… ì‹¤í–‰ - MongoDB ì €ì¥ ê¸°ëŠ¥ ì¶”ê°€"""
        try:
            task.is_running = True
            logger.info(f"  {stage_name}-{task_index}: {task.name} ì‹¤í–‰ ì¤‘...")
            
            start_time = datetime.now()
            result = await asyncio.wait_for(task.func(), timeout=180)
            duration = (datetime.now() - start_time).total_seconds()
            
            if result is not None:
                # ğŸ”§ í•µì‹¬ ì¶”ê°€: ë©”ëª¨ë¦¬ ì €ì¥
                task.last_result = result
                task.error_count = 0  # ì„±ê³µ ì‹œ ì—ëŸ¬ ì¹´ìš´íŠ¸ ë¦¬ì…‹
                
                # ğŸ”§ í•µì‹¬ ì¶”ê°€: MongoDB ì €ì¥ (resultê°€ Noneì´ ì•„ë‹ ë•Œë§Œ)
                logger.info(f"ì‘ì—… ê²°ê³¼ ì €ì¥ ì‹œë„: {task.name} (ê²°ê³¼ íƒ€ì…: {type(result)})")
                self._update_cache(task, result)
                
                # ê²°ê³¼ ìš”ì•½ ë¡œê¹…
                result_summary = self._get_result_summary(task.name, result)
                logger.info(f"    âœ… {task.name} ì„±ê³µ ({duration:.1f}ì´ˆ) - {result_summary}")
                return True
            else:
                task.error_count += 1
                logger.warning(f"    âŒ {task.name} ì‹¤íŒ¨ (ê²°ê³¼ê°€ None) - MongoDB ì €ì¥í•˜ì§€ ì•ŠìŒ")
                return False
                
        except asyncio.TimeoutError:
            task.error_count += 1
            logger.error(f"    â° {task.name} íƒ€ì„ì•„ì›ƒ (180ì´ˆ)")
            return False
        except Exception as e:
            task.error_count += 1
            logger.error(f"    ğŸ’¥ {task.name} ì˜¤ë¥˜: {e}")
            return False
        finally:
            task.is_running = False

    async def run_cycle(self, force_all_analysis=False) -> Dict:
        """í•œ ì‚¬ì´í´ ì§ë ¬ ì‹¤í–‰ - ì´ˆê¸° ì‹¤í–‰ ê°•ì œ ë¶„ì„ ë¡œì§ ìˆ˜ì •"""
        self.global_cycle_count += 1
        cycle_start = datetime.now()
        
        logger.info(f"=== ì§ë ¬ ì‚¬ì´í´ #{self.global_cycle_count} ì‹œì‘ (MongoDB ì €ì¥ í¬í•¨) ===")
        if force_all_analysis:
            logger.info("ğŸ”¥ ì´ˆê¸° ì‹¤í–‰ ëª¨ë“œ: ëª¨ë“  AI ë¶„ì„ ê°•ì œ ì‹¤í–‰")
        
        total_tasks_run = 0
        total_tasks_success = 0
        stage_results = {}
        
        # ê° ë‹¨ê³„ë³„ë¡œ ìˆœì°¨ ì‹¤í–‰
        for stage_idx, stage in enumerate(self.execution_stages, 1):
            stage_start = datetime.now()
            
            # í•´ë‹¹ ë‹¨ê³„ì˜ ì‹¤í–‰í•  ì‘ì—…ë“¤ ì„ ë³„
            stage_tasks = []
            skipped_tasks = []
            
            for task_name, task in self.tasks.items():
                if task.stage == stage:
                    # ğŸ”§ ìˆ˜ì •: force_all_analysisë¥¼ should_run_taskì— ì „ë‹¬
                    should_run, reason = self.should_run_task(task, force_all_analysis)
                    
                    if should_run:
                        stage_tasks.append((task_name, task))
                    else:
                        skipped_tasks.append((task_name, reason))
            
            if not stage_tasks and not skipped_tasks:
                continue  # í•´ë‹¹ ë‹¨ê³„ì— ì‘ì—…ì´ ì—†ìŒ
            
            logger.info(f"{stage_idx}ë‹¨ê³„: {stage} ({len(stage_tasks)}ê°œ ì‹¤í–‰, {len(skipped_tasks)}ê°œ ìŠ¤í‚µ)")
            
            # ë‹¨ê³„ ë‚´ ì‘ì—…ë“¤ ìˆœì°¨ ì‹¤í–‰
            stage_success = 0
            for i, (task_name, task) in enumerate(stage_tasks, 1):
                success = await self.run_task(task, stage, i, len(stage_tasks))
                total_tasks_run += 1
                if success:
                    stage_success += 1
                    total_tasks_success += 1
                
                # ì‘ì—… ê°„ ì§§ì€ ëŒ€ê¸° (AI ë¶„ì„ì˜ ê²½ìš°)
                if task_name.startswith('ai_') and i < len(stage_tasks):
                    await asyncio.sleep(0.5)
            
            stage_duration = (datetime.now() - stage_start).total_seconds()
            stage_results[stage] = {
                'tasks_run': len(stage_tasks),
                'tasks_success': stage_success,
                'duration_seconds': stage_duration
            }
            
            if stage_tasks:
                logger.info(f"  {stage} ì™„ë£Œ: {stage_success}/{len(stage_tasks)} ì„±ê³µ ({stage_duration:.1f}ì´ˆ)")
            
            # ë‹¨ê³„ ê°„ ëŒ€ê¸° (ë°ì´í„° ì•ˆì •í™”)
            if stage_idx < len(self.execution_stages):
                await asyncio.sleep(0.5)
        
        cycle_duration = (datetime.now() - cycle_start).total_seconds()
        
        logger.info(f"=== ì§ë ¬ ì‚¬ì´í´ #{self.global_cycle_count} ì™„ë£Œ ({cycle_duration:.1f}ì´ˆ) ===")
        logger.info(f"ì „ì²´ ì„±ê³µë¥ : {total_tasks_success}/{total_tasks_run} (MongoDB ì €ì¥ í¬í•¨)")
        
        # ì´ˆê¸° ì‹¤í–‰ ê²°ê³¼ ìš”ì•½
        if force_all_analysis:
            ai_tasks_run = sum(1 for stage_result in stage_results.values() 
                            for task_name in [t[0] for t in stage_tasks] 
                            if task_name.startswith('ai_'))
            logger.info(f"ğŸ”¥ ì´ˆê¸° ì‹¤í–‰ ì™„ë£Œ: AI ë¶„ì„ {ai_tasks_run}ê°œ ì‹¤í–‰ ë° MongoDB ì €ì¥")
        
        return {
            'success': True,
            'cycle_count': self.global_cycle_count,
            'tasks_run': total_tasks_run,
            'tasks_success': total_tasks_success,
            'duration_seconds': cycle_duration,
            'stage_results': stage_results,
            'forced_all_analysis': force_all_analysis,
            'mongodb_enabled': True
        }

    def _get_result_summary(self, task_name: str, result) -> str:
        """ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        try:
            if task_name == "chart_update":
                return f"ì°¨íŠ¸ ì—…ë°ì´íŠ¸ {'ì„±ê³µ' if result else 'ì‹¤íŒ¨'}"
            elif task_name == "position_data":
                if isinstance(result, dict):
                    positions = result.get('positions', '[]')
                    pos_count = len(eval(positions)) if positions != '[]' else 0
                    balance = result.get('balance', {}).get('USDT', {}).get('total', 0) if result.get('balance') else 0
                    return f"í¬ì§€ì…˜ {pos_count}ê°œ, ì”ê³  {balance:.2f} USDT"
                return "í¬ì§€ì…˜ ë°ì´í„° ìˆ˜ì§‘ë¨"
            elif task_name.startswith('ai_'):
                if isinstance(result, dict) and result.get('success'):
                    confidence = result.get('confidence', result.get('analysis_confidence', 0))
                    signal = result.get('investment_signal', result.get('btc_signal', result.get('final_decision', 'N/A')))
                    return f"{signal} (ì‹ ë¢°ë„: {confidence}%)"
                else:
                    error = result.get('error', 'unknown') if isinstance(result, dict) else 'unknown'
                    return f"ë¶„ì„ ì‹¤íŒ¨: {error}"
            elif task_name == "final_decision":
                if isinstance(result, dict) and result.get('success'):
                    decision_result = result.get('result', {})
                    action = decision_result.get('final_decision', 'N/A')
                    confidence = decision_result.get('decision_confidence', 0)
                    return f"{action} (ì‹ ë¢°ë„: {confidence}%)"
                else:
                    error = result.get('error', 'unknown') if isinstance(result, dict) else 'unknown'
                    return f"ê²°ì • ì‹¤íŒ¨: {error}"
            else:
                return "ì™„ë£Œ"
        except Exception:
            return "ìš”ì•½ ì‹¤íŒ¨"
    
    def get_data(self, task_name: str) -> any:
        """ë°ì´í„° ìš”ì²­ - ìºì‹œ ìš°ì„ , ë©”ëª¨ë¦¬ ë°±ì—…"""
        if task_name not in self.tasks:
            logger.error(f"ë“±ë¡ë˜ì§€ ì•Šì€ ì‘ì—…: {task_name}")
            return None
        
        task = self.tasks[task_name]
        
        if task.error_count >= task.max_errors:
            logger.warning(f"ë¹„í™œì„±í™”ëœ ì‘ì—…: {task_name}")
            return None
        
        # ğŸ”§ í•µì‹¬ ìˆ˜ì •: ìºì‹œ ìš°ì„ , ë©”ëª¨ë¦¬ ë°±ì—…
        # 1. MongoDB ìºì‹œì—ì„œ ë¨¼ì € ì¡°íšŒ
        cached_data = self.get_cached_data(task_name)
        if cached_data is not None:
            logger.debug(f"MongoDB ìºì‹œ ë°ì´í„° ì‚¬ìš©: {task_name}")
            return cached_data
        
        # 2. ìºì‹œì— ì—†ìœ¼ë©´ ë©”ëª¨ë¦¬ì—ì„œ ì¡°íšŒ
        if task.last_result is not None:
            logger.debug(f"ë©”ëª¨ë¦¬ ë°ì´í„° ì‚¬ìš©: {task_name}")
            return task.last_result
        
        # 3. ë‘˜ ë‹¤ ì—†ìœ¼ë©´ None
        logger.warning(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì—†ìŒ: {task_name}")
        return None
    
    async def get_all_analysis_for_decision(self) -> Dict:
        """ìµœì¢… ê²°ì •ìš© ëª¨ë“  ë¶„ì„ ê²°ê³¼ ë°˜í™˜ - í¬ì§€ì…˜ ì¡°ê±´ë¶€ ì²˜ë¦¬ ì¶”ê°€"""
        try:
            logger.info("ğŸ” DEBUG: get_all_analysis_for_decision ì‹œì‘")
            results = {}
            
            # AI ë¶„ì„ ê²°ê³¼ ë§¤í•‘
            ai_mapping = {
                'ai_technical_analysis': 'technical_analysis',
                'ai_sentiment_analysis': 'sentiment_analysis',
                'ai_macro_analysis': 'macro_analysis',
                'ai_onchain_analysis': 'onchain_analysis',
                'ai_institutional_analysis': 'institutional_analysis'
            }
            
            # ğŸ” ë””ë²„ê¹…: AI ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘
            for ai_task, result_key in ai_mapping.items():
                try:
                    logger.info(f"ğŸ” DEBUG: {ai_task} ë°ì´í„° ì¡°íšŒ ì¤‘...")
                    data = self.get_data(ai_task)
                    
                    logger.info(f"ğŸ” DEBUG: {ai_task} ê²°ê³¼ íƒ€ì…: {type(data)}")
                    logger.info(f"ğŸ” DEBUG: {ai_task} ê²°ê³¼ê°€ None: {data is None}")
                    
                    if data:
                        if isinstance(data, dict):
                            logger.info(f"ğŸ” DEBUG: {ai_task} ê²°ê³¼ í‚¤ë“¤: {list(data.keys())}")
                            if 'success' in data:
                                logger.info(f"ğŸ” DEBUG: {ai_task} success: {data.get('success')}")
                        results[result_key] = data
                        logger.info(f"ğŸ” DEBUG: {result_key} ì„¤ì • ì™„ë£Œ")
                    else:
                        logger.warning(f"ğŸ” DEBUG: {ai_task} ê²°ê³¼ ì—†ìŒ")
                        results[result_key] = {
                            'success': False,
                            'error': f'{ai_task} ê²°ê³¼ ì—†ìŒ',
                            'skip_reason': 'no_result'
                        }
                except Exception as e:
                    logger.error(f"ğŸ” DEBUG: {ai_task} ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    results[result_key] = {'success': False, 'error': str(e)}
            
            # ğŸ”§ í˜„ì¬ í¬ì§€ì…˜ ì •ë³´ ë¨¼ì € ìˆ˜ì§‘ ë° í™•ì¸
            logger.info("ğŸ” DEBUG: í˜„ì¬ í¬ì§€ì…˜ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
            position_data = self.get_data('position_data')
            
            logger.info(f"ğŸ” DEBUG: position_data íƒ€ì…: {type(position_data)}")
            logger.info(f"ğŸ” DEBUG: position_dataê°€ None: {position_data is None}")
            
            if position_data:
                if isinstance(position_data, dict):
                    logger.info(f"ğŸ” DEBUG: position_data í‚¤ë“¤: {list(position_data.keys())}")
                current_position = self._extract_position_info(position_data)
                results['current_position'] = current_position
                has_position = current_position.get('has_position', False)
                logger.info(f"ğŸ” DEBUG: í¬ì§€ì…˜ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ - has_position: {has_position}")
            else:
                logger.warning("ğŸ” DEBUG: position_dataê°€ None - ê¸°ë³¸ê°’ ì‚¬ìš©")
                current_position = {
                    'has_position': False,
                    'side': 'none',
                    'size': 0,
                    'entry_price': 0
                }
                results['current_position'] = current_position
                has_position = False
            
            # ğŸ”§ í¬ì§€ì…˜ ë¶„ì„ (í¬ì§€ì…˜ ìœ ë¬´ì— ë”°ë¼ ì¡°ê±´ë¶€ ì‹¤í–‰)
            logger.info("ğŸ” DEBUG: í¬ì§€ì…˜ ë¶„ì„ ì‹œì‘")
            try:
                logger.info(f"ğŸ” DEBUG: í¬ì§€ì…˜ ìƒíƒœ - has_position: {has_position}")
                
                if has_position:
                    # í¬ì§€ì…˜ì´ ìˆì„ ë•Œë§Œ ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
                    logger.info("ğŸ” DEBUG: í¬ì§€ì…˜ ìˆìŒ - ì‹¤ì œ position_analysis ì‹¤í–‰")
                    from docs.investment_ai.analyzers.position_analyzer import analyze_position_status
                    
                    # analyze_position_status í•¨ìˆ˜ í˜¸ì¶œ - ë¹„ë™ê¸° í•¨ìˆ˜ ì²˜ë¦¬
                    import inspect
                    if inspect.iscoroutinefunction(analyze_position_status):
                        logger.info("ğŸ” DEBUG: position_analyzerê°€ ë¹„ë™ê¸° í•¨ìˆ˜ì„ - awaitë¡œ í˜¸ì¶œ")
                        # ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ awaitë¡œ í˜¸ì¶œ (ë™ê¸° í•¨ìˆ˜ì—ì„œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
                        try:
                            # asyncio.runì„ ì‚¬ìš©í•´ì„œ ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
                            import asyncio
                            if asyncio.get_running_loop():
                                # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ìˆìœ¼ë©´ ìƒˆ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰
                                position_analysis = await analyze_position_status()
                            else:
                                # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ë§Œë“¤ì–´ì„œ ì‹¤í–‰
                                position_analysis = asyncio.run(analyze_position_status())
                        except RuntimeError:
                            # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ì—ì„œ ìƒˆ ë£¨í”„ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’
                            logger.warning("ğŸ” DEBUG: ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ì—ì„œ position_analyzer í˜¸ì¶œ ë¶ˆê°€ - ê¸°ë³¸ê°’ ì‚¬ìš©")
                            position_analysis = {
                                'success': True,
                                'result': {
                                    'recommended_action': 'Wait',
                                    'position_status': 'Running Loop Conflict',
                                    'risk_level': 'None',
                                    'confidence': 50
                                },
                                'note': 'Event loop conflict - using default'
                            }
                    else:
                        position_analysis = analyze_position_status()
                        
                        logger.info(f"ğŸ” DEBUG: ì‹¤ì œ í¬ì§€ì…˜ ë¶„ì„ ê²°ê³¼ íƒ€ì…: {type(position_analysis)}")
                        logger.info(f"ğŸ” DEBUG: ì‹¤ì œ í¬ì§€ì…˜ ë¶„ì„ ê²°ê³¼ê°€ None: {position_analysis is None}")
                        
                        if position_analysis and isinstance(position_analysis, dict):
                            logger.info(f"ğŸ” DEBUG: ì‹¤ì œ í¬ì§€ì…˜ ë¶„ì„ í‚¤ë“¤: {list(position_analysis.keys())}")
                            if 'success' in position_analysis:
                                logger.info(f"ğŸ” DEBUG: ì‹¤ì œ í¬ì§€ì…˜ ë¶„ì„ success: {position_analysis.get('success')}")
                else:
                    # í¬ì§€ì…˜ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
                    logger.info("ğŸ” DEBUG: í¬ì§€ì…˜ ì—†ìŒ - ê¸°ë³¸ê°’ position_analysis ì„¤ì •")
                    position_analysis = {
                        'success': True,
                        'result': {
                            'recommended_action': 'Wait',
                            'position_status': 'No Position',
                            'risk_level': 'None',
                            'confidence': 100,
                            'analysis_summary': 'í˜„ì¬ í¬ì§€ì…˜ì´ ì—†ì–´ ëŒ€ê¸° ìƒíƒœ ê¶Œì¥',
                            'position_health': 'N/A - No Position'
                        },
                        'analysis_type': 'position_analysis',
                        'note': 'No position - default analysis'
                    }
                
                if position_analysis and position_analysis.get('success', False):
                    results['position_analysis'] = position_analysis
                    logger.info("ğŸ” DEBUG: í¬ì§€ì…˜ ë¶„ì„ ì„±ê³µ")
                else:
                    logger.warning("ğŸ” DEBUG: í¬ì§€ì…˜ ë¶„ì„ ì‹¤íŒ¨")
                    error_msg = position_analysis.get('error', 'í¬ì§€ì…˜ ë¶„ì„ ì‹¤íŒ¨') if isinstance(position_analysis, dict) else 'í¬ì§€ì…˜ ë¶„ì„ ì‹¤íŒ¨'
                    results['position_analysis'] = {
                        'success': False, 
                        'error': error_msg,
                        'skip_reason': position_analysis.get('skip_reason', 'analysis_failed') if isinstance(position_analysis, dict) else 'analysis_failed'
                    }
                    
            except Exception as e:
                logger.error(f"ğŸ” DEBUG: í¬ì§€ì…˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                results['position_analysis'] = {
                    'success': False,
                    'error': f'í¬ì§€ì…˜ ë¶„ì„ ì˜¤ë¥˜: {str(e)}',
                    'skip_reason': 'position_analysis_error'
                }
            
            # ğŸ” ë””ë²„ê¹…: ìµœì¢… ê²°ê³¼ ìš”ì•½
            logger.info(f"ğŸ” DEBUG: ìµœì¢… ê²°ê³¼ í‚¤ë“¤: {list(results.keys())}")
            for key, value in results.items():
                if isinstance(value, dict) and 'success' in value:
                    logger.info(f"ğŸ” DEBUG: {key} success: {value.get('success')}")
                
            return results
            
        except Exception as e:
            logger.error(f"ğŸ” DEBUG: get_all_analysis_for_decision ì „ì²´ ì˜¤ë¥˜: {e}")
            return {}

    def _extract_position_info(self, position_data) -> Dict:
        """í¬ì§€ì…˜ ë°ì´í„°ì—ì„œ í˜„ì¬ í¬ì§€ì…˜ ì •ë³´ ì¶”ì¶œ - ì•ˆì „ì„± ê°•í™”"""
        try:
            # ê¸°ë³¸ê°’
            position_info = {
                'has_position': False,
                'side': 'none',
                'size': 0,
                'entry_price': 0,
                'unrealized_pnl': 0,
                'total_equity': 0,
                'available_balance': 0
            }
            
            # ğŸ”§ ìˆ˜ì •: position_dataê°€ Noneì´ê±°ë‚˜ ì˜ëª»ëœ í˜•íƒœ ì²´í¬
            if not position_data or not isinstance(position_data, dict):
                logger.warning("í¬ì§€ì…˜ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ì˜ëª»ëœ í˜•íƒœ")
                return position_info
            
            # ì”ê³  ì •ë³´
            balance = position_data.get('balance', {})
            if isinstance(balance, dict) and 'USDT' in balance:
                usdt_balance = balance['USDT']
                # ğŸ”§ ìˆ˜ì •: None ê°’ ì²´í¬ ì¶”ê°€
                total = usdt_balance.get('total', 0)
                free = usdt_balance.get('free', 0)
                if total is not None and free is not None:
                    position_info.update({
                        'total_equity': float(total),
                        'available_balance': float(free)
                    })
            
            # positionsì—ì„œ BTC í¬ì§€ì…˜ ì°¾ê¸°
            positions = position_data.get('positions', [])
            if isinstance(positions, str):
                import json
                try:
                    positions = json.loads(positions)
                except:
                    logger.warning("í¬ì§€ì…˜ JSON íŒŒì‹± ì‹¤íŒ¨")
                    return position_info
            
            if not isinstance(positions, list):
                logger.warning("í¬ì§€ì…˜ ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜")
                return position_info
            
            for pos in positions:
                if not isinstance(pos, dict):
                    continue
                    
                symbol = pos.get('symbol', '')
                if 'BTC' in symbol:
                    # ğŸ”§ ìˆ˜ì •: None ê°’ ì²´í¬ ê°•í™”
                    size_raw = pos.get('size', pos.get('contracts', 0))
                    entry_price_raw = pos.get('avgPrice', pos.get('entryPrice', 0))
                    unrealized_pnl_raw = pos.get('unrealizedPnl', 0)
                    
                    # None ì²´í¬ í›„ float ë³€í™˜
                    try:
                        size = float(size_raw) if size_raw is not None else 0
                        entry_price = float(entry_price_raw) if entry_price_raw is not None else 0
                        unrealized_pnl = float(unrealized_pnl_raw) if unrealized_pnl_raw is not None else 0
                    except (ValueError, TypeError) as e:
                        logger.warning(f"í¬ì§€ì…˜ ìˆ˜ì¹˜ ë³€í™˜ ì‹¤íŒ¨: {e}")
                        continue
                    
                    if abs(size) > 0:
                        # side í•„ë“œë¥¼ ì§ì ‘ ì‚¬ìš©í•´ì•¼ í•¨
                        api_side = pos.get('side', '')
                        position_info.update({
                            'has_position': True,
                            'side': 'long' if api_side == 'Buy' else 'short',
                            'size': abs(size),
                            'entry_price': entry_price,
                            'unrealized_pnl': unrealized_pnl
                        })
                    break
            
            return position_info
        except Exception as e:
            logger.error(f"í¬ì§€ì…˜ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {
                'has_position': False,
                'side': 'none',
                'size': 0,
                'entry_price': 0,
                'error': str(e)
            }
    
    def get_status(self) -> Dict:
        """ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ë°˜í™˜ - MongoDB ìºì‹œ ì •ë³´ í¬í•¨"""
        status = {
            'global_cycle_count': self.global_cycle_count,
            'next_cycle_in_minutes': self.main_cycle_minutes,
            'execution_stages': self.execution_stages,
            'tasks_by_stage': {},
            'tasks': {},
            'mongodb_connected': self.cache_collection is not None
        }
        
        # ë‹¨ê³„ë³„ ì‘ì—… ì •ë¦¬
        for stage in self.execution_stages:
            stage_tasks = []
            for task_name, task in self.tasks.items():
                if task.stage == stage:
                    stage_tasks.append(task_name)
            status['tasks_by_stage'][stage] = stage_tasks
        
        # ê°œë³„ ì‘ì—… ìƒíƒœ - MongoDB ìºì‹œ ìƒíƒœ í¬í•¨
        for task_name, task in self.tasks.items():
            next_run_cycle = (
                (task.interval_cycles - (self.global_cycle_count % task.interval_cycles)) 
                % task.interval_cycles
            )
            
            should_run, reason = self.should_run_task(task)
            
            # MongoDB ìºì‹œ ìƒíƒœ í™•ì¸
            has_cache = False
            cache_age_minutes = 0
            
            if self.cache_collection is not None:
                try:
                    cache_doc = self.cache_collection.find_one({"task_name": task_name})
                    if cache_doc:
                        has_cache = True
                        if cache_doc.get("created_at"):
                            created_at = cache_doc["created_at"]
                            
                            # timezone ì •ë³´ í™•ì¸ ë° ë³€í™˜
                            if created_at.tzinfo is None:
                                # timezone-naiveì¸ ê²½ìš° UTCë¡œ ê°€ì •
                                created_at = created_at.replace(tzinfo=timezone.utc)
                            
                            cache_age = datetime.now(timezone.utc) - created_at
                            cache_age_minutes = cache_age.total_seconds() / 60
                except Exception as e:
                    logger.error(f"ìºì‹œ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")
            
            status['tasks'][task_name] = {
                'stage': task.stage,
                'interval_cycles': task.interval_cycles,
                'interval_minutes': task.interval_cycles * self.main_cycle_minutes,
                'cache_duration_minutes': task.cache_duration_minutes,
                'has_result': task.last_result is not None,
                'has_cache': has_cache,
                'cache_age_minutes': round(cache_age_minutes, 1),
                'error_count': task.error_count,
                'is_disabled': task.error_count >= task.max_errors,
                'is_running': task.is_running,
                'next_run_in_cycles': next_run_cycle,
                'next_run_in_minutes': next_run_cycle * self.main_cycle_minutes,
                'dependencies': task.dependencies,
                'current_status': reason,
                'ready_to_run': should_run
            }
        
        return status
    
    def get_final_decision_result(self) -> Dict:
        """ìµœì¢… ê²°ì • ê²°ê³¼ ë°˜í™˜ - ìºì‹œ ìš°ì„ """
        final_task = self.tasks.get('final_decision')
        if final_task:
            # ìºì‹œì—ì„œ ë¨¼ì € ì¡°íšŒ
            cached_result = self.get_cached_data('final_decision')
            if cached_result:
                return cached_result
            
            # ìºì‹œì— ì—†ìœ¼ë©´ ë©”ëª¨ë¦¬ì—ì„œ ì¡°íšŒ
            if final_task.last_result:
                return final_task.last_result
        
        return {
            'success': False,
            'error': 'ìµœì¢… ê²°ì • ê²°ê³¼ ì—†ìŒ',
            'result': {
                'final_decision': 'Hold',
                'decision_confidence': 0,
                'needs_human_review': True,
                'human_review_reason': 'ìµœì¢… ê²°ì • ë¯¸ì™„ë£Œ'
            }
        }
    
    def reset_errors(self, task_name: str = None):
        """ì—ëŸ¬ ì¹´ìš´íŠ¸ ë¦¬ì…‹"""
        if task_name:
            if task_name in self.tasks:
                old_count = self.tasks[task_name].error_count
                self.tasks[task_name].error_count = 0
                logger.info(f"ì—ëŸ¬ ë¦¬ì…‹: {task_name} ({old_count} â†’ 0)")
        else:
            reset_count = 0
            for task in self.tasks.values():
                if task.error_count > 0:
                    task.error_count = 0
                    reset_count += 1
            logger.info(f"ëª¨ë“  ì‘ì—… ì—ëŸ¬ ë¦¬ì…‹: {reset_count}ê°œ")
    
    def clear_cache(self, task_name: str = None):
        """MongoDB ìºì‹œ ì‚­ì œ"""
        if self.cache_collection is None:
            logger.warning("MongoDB ì—°ê²°ë˜ì§€ ì•ŠìŒ - ìºì‹œ ì‚­ì œ ë¶ˆê°€")
            return False
        
        try:
            if task_name:
                # íŠ¹ì • ì‘ì—… ìºì‹œ ì‚­ì œ
                result = self.cache_collection.delete_many({"task_name": task_name})
                logger.info(f"ìºì‹œ ì‚­ì œ: {task_name} ({result.deleted_count}ê°œ ë¬¸ì„œ)")
                return result.deleted_count > 0
            else:
                # ëª¨ë“  ìºì‹œ ì‚­ì œ
                result = self.cache_collection.delete_many({})
                logger.info(f"ëª¨ë“  ìºì‹œ ì‚­ì œ: {result.deleted_count}ê°œ ë¬¸ì„œ")
                return result.deleted_count > 0
        except Exception as e:
            logger.error(f"ìºì‹œ ì‚­ì œ ì˜¤ë¥˜: {e}")
            return False
    
    def get_cache_info(self) -> Dict:
        """MongoDB ìºì‹œ ìƒíƒœ ì •ë³´"""
        if self.cache_collection is None:
            return {'error': 'MongoDB ì—°ê²°ë˜ì§€ ì•ŠìŒ'}
        
        try:
            # ì „ì²´ ìºì‹œ ë¬¸ì„œ ìˆ˜
            total_count = self.cache_collection.count_documents({})
            
            # ë§Œë£Œëœ ìºì‹œ ìˆ˜ (ìˆ˜ë™ ê³„ì‚°)
            expired_count = self.cache_collection.count_documents({
                "expire_at": {"$lt": datetime.now(timezone.utc)}
            })
            
            # ì‘ì—…ë³„ ìºì‹œ ìƒíƒœ
            task_cache_info = {}
            for task_name in self.tasks.keys():
                task_docs = self.cache_collection.count_documents({"task_name": task_name})
                active_docs = self.cache_collection.count_documents({
                    "task_name": task_name,
                    "expire_at": {"$gt": datetime.now(timezone.utc)}
                })
                
                task_cache_info[task_name] = {
                    'total_docs': task_docs,
                    'active_docs': active_docs,
                    'expired_docs': task_docs - active_docs
                }
            
            return {
                'total_documents': total_count,
                'expired_documents': expired_count,
                'active_documents': total_count - expired_count,
                'task_cache_info': task_cache_info,
                'mongodb_connected': True
            }
        except Exception as e:
            logger.error(f"ìºì‹œ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    # ========== ì‘ì—… í•¨ìˆ˜ë“¤ (ë¶„ì„ê¸° í˜¸ì¶œë§Œ) ==========
    
    async def _get_position_data(self):
        """í¬ì§€ì…˜ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            from docs.get_current import fetch_investment_status
            balance, positions_json, ledger = fetch_investment_status()
            
            if balance == 'error':
                return None
            
            return {
                'balance': balance,
                'positions': positions_json,
                'ledger': ledger[:10] if ledger else [],
                'timestamp': datetime.now(timezone.utc).isoformat()
            }
        except Exception as e:
            logger.error(f"í¬ì§€ì…˜ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return None
    
    async def _update_chart_data(self):
        """ì°¨íŠ¸ ë°ì´í„° ì—…ë°ì´íŠ¸ - ì´ˆê¸°/í‰ìƒì‹œ êµ¬ë¶„"""
        try:
            # ğŸ”§ ì´ˆê¸° ì‹¤í–‰ ì—¬ë¶€ í™•ì¸ (ì‚¬ì´í´ 1ì´ê±°ë‚˜ ìºì‹œëœ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì´ˆê¸°)
            is_initial_run = (self.global_cycle_count <= 1) or (self.get_cached_data("chart_update") is None)
            
            if is_initial_run:
                # ì´ˆê¸° ì‹¤í–‰: ì „ì²´ ì°¨íŠ¸ ë°ì´í„° ìˆ˜ì§‘
                logger.info("ğŸ”„ ì´ˆê¸° ì°¨íŠ¸ ë°ì´í„° ì „ì²´ ìˆ˜ì§‘ ì‹œì‘")
                from docs.get_chart import chart_update
                result = chart_update('60m', 'BTCUSDT')  # 15m â†’ 60mìœ¼ë¡œ ë³€ê²½
                
                return {
                    'success': result is not None,
                    'mode': 'full_update',
                    'message': 'ì „ì²´ ì°¨íŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ',
                    'timestamp': datetime.now(timezone.utc).isoformat()
                }
            else:
                # í‰ìƒì‹œ: ìµœì‹  60ë¶„ë´‰ë§Œ ì—…ë°ì´íŠ¸
                logger.info("ğŸ”„ ì°¨íŠ¸ ë°ì´í„° ìµœì‹ ë´‰ ì—…ë°ì´íŠ¸")
                from docs.get_chart import chart_update_one
                result, server_time, execution_time = chart_update_one('60m', 'BTCUSDT')  # 15m â†’ 60mìœ¼ë¡œ ë³€ê²½
                
                return {
                    'success': result is not None,
                    'mode': 'incremental_update',
                    'server_time': server_time,
                    'execution_time': execution_time,
                    'message': 'ìµœì‹  ì°¨íŠ¸ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ',
                    'timestamp': datetime.now(timezone.utc).isoformat()
                }
                
        except Exception as e:
            logger.error(f"ì°¨íŠ¸ ë°ì´í„° ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
            return {
                'success': False,
                'error': str(e),
                'timestamp': datetime.now(timezone.utc).isoformat()
            }
    
    # AI ë¶„ì„ í•¨ìˆ˜ë“¤ (ë¶„ì„ê¸° ì§ì ‘ í˜¸ì¶œ)
    async def _ai_technical_analysis(self):
        """ê¸°ìˆ ì  ë¶„ì„"""
        try:
            from docs.investment_ai.analyzers.technical_analyzer import analyze_technical_indicators
            return await analyze_technical_indicators('BTCUSDT', '60m', 300)  # 15m â†’ 60mìœ¼ë¡œ ë³€ê²½
        except Exception as e:
            logger.error(f"ê¸°ìˆ ì  ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None
    
    async def _ai_sentiment_analysis(self):
        """ê°ì • ë¶„ì„"""
        try:
            from docs.investment_ai.analyzers.sentiment_analyzer import analyze_market_sentiment
            return await analyze_market_sentiment()
        except Exception as e:
            logger.error(f"ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None
    
    async def _ai_macro_analysis(self):
        """ê±°ì‹œê²½ì œ ë¶„ì„"""
        try:
            from docs.investment_ai.analyzers.macro_analyzer import analyze_macro_economics
            return await analyze_macro_economics()
        except Exception as e:
            logger.error(f"ê±°ì‹œê²½ì œ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None
    
    async def _ai_onchain_analysis(self):
        """ì˜¨ì²´ì¸ ë¶„ì„"""
        try:
            from docs.investment_ai.analyzers.onchain_analyzer import analyze_onchain_data
            return await analyze_onchain_data()
        except Exception as e:
            logger.error(f"ì˜¨ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None
    
    async def _ai_institutional_analysis(self):
        """ê¸°ê´€íˆ¬ì ë¶„ì„"""
        try:
            from docs.investment_ai.analyzers.institution_analyzer import analyze_institutional_flow
            return await analyze_institutional_flow()
        except Exception as e:
            logger.error(f"ê¸°ê´€íˆ¬ì ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None
    
    async def _final_decision(self):
        """ìµœì¢… ê²°ì • - ì½”ë£¨í‹´ ì—ëŸ¬ ìˆ˜ì •"""
        try:
            # ğŸ”§ ìˆ˜ì •: ë™ê¸°ì ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘
            all_analysis_results = await self.get_all_analysis_for_decision()
            
            if not all_analysis_results:
                logger.warning("ë¶„ì„ ê²°ê³¼ê°€ ì—†ì–´ ìµœì¢… ê²°ì • ë¶ˆê°€")
                return {
                    'success': False,
                    'error': 'ë¶„ì„ ê²°ê³¼ ì—†ìŒ',
                    'result': {
                        'final_decision': 'Hold',
                        'decision_confidence': 0,
                        'needs_human_review': True,
                        'human_review_reason': 'ë¶„ì„ ê²°ê³¼ ì—†ìŒ'
                    }
                }
            
            # ì„±ê³µí•œ ë¶„ì„ ê°œìˆ˜ í™•ì¸
            success_count = sum(1 for result in all_analysis_results.values() 
                              if isinstance(result, dict) and result.get('success', False))
            total_count = len([k for k in all_analysis_results.keys() if k != 'current_position'])
            
            logger.info(f"ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘ ì™„ë£Œ: {success_count}/{total_count} ì„±ê³µ")
            
            # ìµœì¢… ê²°ì • ì‹¤í–‰
            from docs.investment_ai.final_decisionmaker import make_final_investment_decision
            return await make_final_investment_decision(all_analysis_results)
        except Exception as e:
            logger.error(f"ìµœì¢… ê²°ì • ì˜¤ë¥˜: {e}")
            return {
                'success': False,
                'error': str(e),
                'result': {
                    'final_decision': 'Hold',
                    'decision_confidence': 0,
                    'needs_human_review': True,
                    'human_review_reason': f'ìµœì¢… ê²°ì • ì˜¤ë¥˜: {str(e)}'
                }
            }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_serial_scheduler: Optional[SerialDataScheduler] = None

def get_serial_scheduler() -> SerialDataScheduler:
    """ì§ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _serial_scheduler
    if _serial_scheduler is None:
        _serial_scheduler = SerialDataScheduler()
    return _serial_scheduler

# í¸ì˜ í•¨ìˆ˜ë“¤
async def run_serial_cycle(force_all_analysis=False):
    """ì§ë ¬ ì‚¬ì´í´ ì‹¤í–‰ - ê°•ì œ ëª¨ë“  ë¶„ì„ ì˜µì…˜ ì¶”ê°€"""
    scheduler = get_serial_scheduler()
    return await scheduler.run_cycle(force_all_analysis=force_all_analysis)

def get_serial_data(task_name: str):
    """ì§ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œ ë°ì´í„° ìš”ì²­"""
    scheduler = get_serial_scheduler()
    return scheduler.get_data(task_name)

def get_serial_status():
    """ì§ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ"""
    scheduler = get_serial_scheduler()
    return scheduler.get_status()

def get_final_decision():
    """ìµœì¢… ê²°ì • ê²°ê³¼"""
    scheduler = get_serial_scheduler()
    return scheduler.get_final_decision_result()

def clear_serial_cache(task_name: str = None):
    """ì§ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ ìºì‹œ ì‚­ì œ"""
    scheduler = get_serial_scheduler()
    return scheduler.clear_cache(task_name)

def get_cache_status():
    """ìºì‹œ ìƒíƒœ ì •ë³´"""
    scheduler = get_serial_scheduler()
    return scheduler.get_cache_info()

def reset_serial_errors(task_name: str = None):
    """ì§ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ ì—ëŸ¬ ë¦¬ì…‹"""
    scheduler = get_serial_scheduler()
    scheduler.reset_errors(task_name)