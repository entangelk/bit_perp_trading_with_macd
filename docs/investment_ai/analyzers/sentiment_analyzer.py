import json
import re
import logging
import requests
import feedparser
from typing import Dict, List, Optional
from datetime import datetime, timezone, timedelta
from google import genai
from google.genai import types
import sys
import os

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '../../../'))

from docs.investment_ai.config import CONFIG, API_KEY, MODEL_PRIORITY

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger("sentiment_analyzer")

class SentimentAnalyzer:
    """ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„ AI - 1ë‹¨ê³„ (ë‰´ìŠ¤ + ê³µí¬/íƒìš• ì§€ìˆ˜)"""
    
    def __init__(self):
        # AI ëª¨ë¸ ì´ˆê¸°í™” ì œê±° - ì‹¤ì œ í˜¸ì¶œ ì‹œì—ë§Œ ì´ˆê¸°í™”
        self.client = None
        self.model_name = None
        
        # ì‹¤íŒ¨ ì¹´ìš´íŠ¸ ì¶”ê°€
        self.error_counts = {
            'fear_greed': 0,
            'news': 0
        }
        self.max_errors = 3  # ìµœëŒ€ í—ˆìš© ì˜¤ë¥˜ ìˆ˜
        
        # ë‰´ìŠ¤ ì†ŒìŠ¤ ì„¤ì •
        self.news_sources = {
            'cointelegraph': 'https://cointelegraph.com/rss',
            'coindesk': 'https://www.coindesk.com/arc/outboundfeeds/rss/',
            'decrypt': 'https://decrypt.co/feed',
            'bitcoinist': 'https://bitcoinist.com/feed/'
        }
        
        # Fear & Greed Index API
        self.fear_greed_api = "https://api.alternative.me/fng/"
    
    def get_fear_greed_index(self, days: int = 7) -> Dict:
        """ê³µí¬/íƒìš• ì§€ìˆ˜ ìˆ˜ì§‘"""
        try:
            # Alternative.me API í˜¸ì¶œ
            response = requests.get(f"{self.fear_greed_api}?limit={days}", timeout=10)
            response.raise_for_status()
            
            data = response.json()
            
            if 'data' not in data:
                raise ValueError("ê³µí¬/íƒìš• ì§€ìˆ˜ ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜")
            
            fear_greed_data = []
            for item in data['data']:
                fear_greed_data.append({
                    'value': int(item['value']),
                    'classification': item['value_classification'],
                    'timestamp': item['timestamp'],
                    'date': datetime.fromtimestamp(int(item['timestamp'])).strftime('%Y-%m-%d')
                })
            
            # ìµœì‹  ë°ì´í„°ì™€ í‰ê·  ê³„ì‚°
            latest = fear_greed_data[0]
            avg_value = sum(item['value'] for item in fear_greed_data) / len(fear_greed_data)
            
            # ì¶”ì„¸ ê³„ì‚° (7ì¼ê°„ ë³€í™”)
            if len(fear_greed_data) >= 7:
                trend = fear_greed_data[0]['value'] - fear_greed_data[6]['value']
                trend_direction = 'increasing' if trend > 5 else 'decreasing' if trend < -5 else 'stable'
            else:
                trend = 0
                trend_direction = 'stable'
            
            result = {
                'current_value': latest['value'],
                'current_classification': latest['classification'],
                'week_average': round(avg_value, 1),
                'trend_change': trend,
                'trend_direction': trend_direction,
                'historical_data': fear_greed_data,
                'market_sentiment': self._classify_market_sentiment(latest['value'])
            }
            
            logger.info(f"ê³µí¬/íƒìš• ì§€ìˆ˜ ìˆ˜ì§‘ ì™„ë£Œ: {latest['value']} ({latest['classification']})")
            return result
            
        except requests.RequestException as e:
            logger.error(f"ê³µí¬/íƒìš• ì§€ìˆ˜ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            self.error_counts['fear_greed'] += 1
            return self._get_cached_fear_greed()
        except Exception as e:
            logger.error(f"ê³µí¬/íƒìš• ì§€ìˆ˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            self.error_counts['fear_greed'] += 1
            return self._get_cached_fear_greed()
    
    def _classify_market_sentiment(self, value: int) -> str:
        """ê³µí¬/íƒìš• ì§€ìˆ˜ ê°’ì„ ì‹œì¥ ì‹¬ë¦¬ë¡œ ë¶„ë¥˜"""
        if value >= 75:
            return "extreme_greed"
        elif value >= 55:
            return "greed"
        elif value >= 45:
            return "neutral"
        elif value >= 25:
            return "fear"
        else:
            return "extreme_fear"
    
    def _get_cached_fear_greed(self) -> Optional[Dict]:
        """MongoDBì—ì„œ ê³¼ê±° ê³µí¬/íƒìš• ì§€ìˆ˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            from pymongo import MongoClient
            from datetime import datetime, timezone, timedelta
            
            client = MongoClient("mongodb://mongodb:27017")
            db = client["bitcoin"]
            cache_collection = db["data_cache"]
            
            # ìµœê·¼ 7ì¼ ì´ë‚´ ë°ì´í„° ì°¾ê¸°
            seven_days_ago = datetime.now(timezone.utc) - timedelta(days=7)
            
            cached_data = cache_collection.find_one({
                "task_name": "fear_greed_index",
                "created_at": {"$gte": seven_days_ago}
            }, sort=[("created_at", -1)])
            
            if cached_data and cached_data.get('data'):
                fg_data = cached_data['data']['data'][0]  # ìµœì‹  ë°ì´í„°
                return {
                    'current_value': int(fg_data['value']),
                    'current_classification': fg_data['value_classification'],
                    'week_average': int(fg_data['value']),  # ë‹¨ì¼ ë°ì´í„°ì´ë¯€ë¡œ ë™ì¼
                    'trend_change': 0,
                    'trend_direction': 'stable',
                    'historical_data': [{
                        'value': int(fg_data['value']),
                        'classification': fg_data['value_classification'],
                        'timestamp': fg_data['timestamp'],
                        'date': datetime.fromtimestamp(int(fg_data['timestamp'])).strftime('%Y-%m-%d')
                    }],
                    'market_sentiment': self._classify_market_sentiment(int(fg_data['value'])),
                    'cached_data_age': str(datetime.now(timezone.utc) - cached_data['created_at'])
                }
            
            logger.warning("ê³µí¬/íƒìš• ì§€ìˆ˜: ìºì‹œëœ ë°ì´í„° ì—†ìŒ")
            return None
            
        except Exception as e:
            logger.error(f"ìºì‹œëœ ê³µí¬/íƒìš• ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def _clean_summary(self, summary: str) -> str:
        """HTML íƒœê·¸ì™€ ë¶ˆí•„ìš”í•œ ë‚´ìš©ì„ ì œê±°í•˜ê³  ìœ ì˜ë¯¸í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if not summary:
            return ""
        
        # HTML íƒœê·¸ ì œê±°
        import re
        clean_text = re.sub(r'<[^>]+>', '', summary)
        
        # HTML ì—”í‹°í‹° ë””ì½”ë”©
        import html
        clean_text = html.unescape(clean_text)
        
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
        clean_text = re.sub(r'\s+', ' ', clean_text).strip()
        
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ì›ë³¸ ë°˜í™˜ (ìµœì†Œ 50ì)
        if len(clean_text) < 50:
            return clean_text[:300] if clean_text else ""
        
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì¤‘ê°„ ë¶€ë¶„ ì¶”ì¶œ
        sentences = re.split(r'[.!?]+', clean_text)
        sentences = [s.strip() for s in sentences if len(s.strip()) > 10]
        
        if len(sentences) <= 1:
            # ë¬¸ì¥ì´ 1ê°œ ì´í•˜ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©
            return clean_text[:300]
        elif len(sentences) == 2:
            # ë¬¸ì¥ì´ 2ê°œë©´ ë‘˜ ë‹¤ ì‚¬ìš©
            return '. '.join(sentences)[:300]
        else:
            # ë¬¸ì¥ì´ 3ê°œ ì´ìƒì´ë©´ ì¤‘ê°„ ë¶€ë¶„ ìš°ì„  ì‚¬ìš©
            if len(sentences) >= 3:
                # ì²« ë²ˆì§¸ ë¬¸ì¥ ì œì™¸í•˜ê³  ì¤‘ê°„ë¶€í„° ì‚¬ìš©
                middle_text = '. '.join(sentences[1:])
                if len(middle_text) >= 100:  # ì¤‘ê°„ ë¶€ë¶„ì´ ì¶©ë¶„íˆ ê¸¸ë©´ ì‚¬ìš©
                    return middle_text[:300]
            
            # ì¤‘ê°„ ë¶€ë¶„ì´ ì§§ìœ¼ë©´ ì „ì²´ ì‚¬ìš©
            return '. '.join(sentences)[:300]

    def get_crypto_news(self, limit: int = 20) -> List[Dict]:
        """ì•”í˜¸í™”í ë‰´ìŠ¤ ìˆ˜ì§‘"""
        try:
            all_news = []
            
            for source_name, rss_url in self.news_sources.items():
                try:
                    # RSS í”¼ë“œ íŒŒì‹±
                    feed = feedparser.parse(rss_url)
                    
                    for entry in feed.entries[:limit//len(self.news_sources)]:
                        # ë¹„íŠ¸ì½”ì¸ ê´€ë ¨ ë‰´ìŠ¤ë§Œ í•„í„°ë§
                        title = entry.get('title', '').lower()
                        summary = entry.get('summary', '').lower()
                        
                        bitcoin_keywords = ['bitcoin', 'btc', 'cryptocurrency', 'crypto']
                        if any(keyword in title or keyword in summary for keyword in bitcoin_keywords):
                            
                            # ë°œí–‰ ì‹œê°„ ì²˜ë¦¬
                            published_time = None
                            if hasattr(entry, 'published_parsed') and entry.published_parsed:
                                published_time = datetime(*entry.published_parsed[:6])
                            elif hasattr(entry, 'published'):
                                try:
                                    published_time = datetime.strptime(entry.published, '%a, %d %b %Y %H:%M:%S %Z')
                                except:
                                    published_time = datetime.now()
                            else:
                                published_time = datetime.now()
                            
                            # 24ì‹œê°„ ì´ë‚´ ë‰´ìŠ¤ë§Œ
                            if published_time > datetime.now() - timedelta(hours=24):
                                # summary ì •ë¦¬ ì²˜ë¦¬
                                clean_summary = self._clean_summary(entry.get('summary', ''))
                                
                                all_news.append({
                                    'title': entry.get('title', ''),
                                    'summary': clean_summary,
                                    'source': source_name,
                                    'published_time': published_time.isoformat(),
                                    'link': entry.get('link', '')
                                })
                                
                except Exception as e:
                    logger.warning(f"{source_name} RSS íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue
            
            # ì‹œê°„ìˆœ ì •ë ¬ (ìµœì‹ ìˆœ)
            all_news.sort(key=lambda x: x['published_time'], reverse=True)
            
            logger.info(f"ì•”í˜¸í™”í ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {len(all_news)}ê°œ")
            return all_news[:limit]
            
        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            self.error_counts['news'] += 1
            return self._get_cached_news()
    
    def _get_cached_news(self) -> Optional[List[Dict]]:
        """MongoDBì—ì„œ ê³¼ê±° ë‰´ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            from pymongo import MongoClient
            from datetime import datetime, timezone, timedelta
            
            client = MongoClient("mongodb://mongodb:27017")
            db = client["bitcoin"]
            cache_collection = db["data_cache"]
            
            # ìµœê·¼ 24ì‹œê°„ ì´ë‚´ ë‰´ìŠ¤ ë°ì´í„° ì°¾ê¸°
            one_day_ago = datetime.now(timezone.utc) - timedelta(days=1)
            
            cached_data = cache_collection.find_one({
                "task_name": "crypto_news",
                "created_at": {"$gte": one_day_ago}
            }, sort=[("created_at", -1)])
            
            if cached_data and cached_data.get('data', {}).get('news'):
                return cached_data['data']['news']
            
            logger.warning("ë‰´ìŠ¤ ë°ì´í„°: ìºì‹œëœ ë°ì´í„° ì—†ìŒ")
            return None
            
        except Exception as e:
            logger.error(f"ìºì‹œëœ ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def analyze_news_sentiment(self, news_list: List[Dict]) -> Dict:
        """ë‰´ìŠ¤ ê°ì • ë¶„ì„ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)"""
        try:
            if not news_list:
                return {
                    'overall_sentiment': 'neutral',
                    'sentiment_score': 0,
                    'positive_count': 0,
                    'negative_count': 0,
                    'neutral_count': 0
                }
            
            # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ
            positive_keywords = [
                'rise', 'surge', 'gain', 'bull', 'bullish', 'pump', 'moon', 'rally',
                'breakthrough', 'adoption', 'institutional', 'etf', 'approval',
                'positive', 'optimistic', 'growth', 'increase', 'up', 'high'
            ]
            
            negative_keywords = [
                'fall', 'drop', 'crash', 'bear', 'bearish', 'dump', 'decline',
                'correction', 'sell-off', 'fear', 'panic', 'regulation', 'ban',
                'negative', 'pessimistic', 'loss', 'decrease', 'down', 'low'
            ]
            
            sentiment_scores = []
            positive_count = 0
            negative_count = 0
            neutral_count = 0
            
            for news in news_list:
                text = f"{news['title']} {news['summary']}".lower()
                
                pos_score = sum(1 for keyword in positive_keywords if keyword in text)
                neg_score = sum(1 for keyword in negative_keywords if keyword in text)
                
                if pos_score > neg_score:
                    sentiment_scores.append(1)
                    positive_count += 1
                elif neg_score > pos_score:
                    sentiment_scores.append(-1)
                    negative_count += 1
                else:
                    sentiment_scores.append(0)
                    neutral_count += 1
            
            # ì „ì²´ ê°ì • ì ìˆ˜
            avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0
            
            # ì „ì²´ ê°ì • ë¶„ë¥˜
            if avg_sentiment > 0.3:
                overall_sentiment = 'positive'
            elif avg_sentiment < -0.3:
                overall_sentiment = 'negative'
            else:
                overall_sentiment = 'neutral'
            
            return {
                'overall_sentiment': overall_sentiment,
                'sentiment_score': round(avg_sentiment, 2),
                'positive_count': positive_count,
                'negative_count': negative_count,
                'neutral_count': neutral_count,
                'total_news': len(news_list)
            }
            
        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                'overall_sentiment': 'neutral',
                'sentiment_score': 0,
                'positive_count': 0,
                'negative_count': 0,
                'neutral_count': 0,
                'error': str(e)
            }
    
    def get_model(self):
        """AI ëª¨ë¸ì„ í•„ìš”í•  ë•Œë§Œ ì´ˆê¸°í™”"""
        if not API_KEY:
            return None, None
            
        try:
            client = genai.Client(api_key=API_KEY)
            
            for model_name in MODEL_PRIORITY:
                try:
                    return client, model_name
                except Exception as e:
                    logger.warning(f"ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„ ëª¨ë¸ {model_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    continue
            
            return None, None
            
        except Exception as e:
            logger.error(f"ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„ ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
            return None, None

    async def analyze_with_ai(self, sentiment_data: Dict) -> Dict:
        """AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‹œì¥ ì‹¬ë¦¬ ì¢…í•© ë¶„ì„"""
        from ..data_scheduler import mark_ai_api_success, mark_ai_api_failure
        
        # í•„ìš”í•  ë•Œë§Œ ëª¨ë¸ ì´ˆê¸°í™”
        if self.client is None:
            self.client, self.model_name = self.get_model()
        
        if self.client is None:
            logger.warning("AI ëª¨ë¸ì´ ì—†ì–´ ê·œì¹™ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            mark_ai_api_failure()
            return self.rule_based_analysis(sentiment_data)
        
        try:
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = CONFIG["prompts"]["sentiment_analysis"].format(
                fear_greed_data=json.dumps(sentiment_data['fear_greed_index'], ensure_ascii=False, indent=2),
                news_data=json.dumps(sentiment_data['news_sentiment'], ensure_ascii=False, indent=2),
                recent_news=json.dumps(sentiment_data['recent_news'][:5], ensure_ascii=False, indent=2)  # ìµœê·¼ 5ê°œ ë‰´ìŠ¤ë§Œ
            )
            
            # AI ëª¨ë¸ì— ì§ˆì˜
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=types.GenerateContentConfig(
                    thinking_config=types.ThinkingConfig(thinking_budget=-1)
                )
            )
            
            # AI API ì„±ê³µ ê¸°ë¡
            mark_ai_api_success()
            
            # JSON íŒŒì‹±
            result_text = response.text
            json_match = re.search(r'\{[\s\S]*\}', result_text)
            if json_match:
                result_json = json.loads(json_match.group(0))
                
                # ë¶„ì„ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                result_json['analysis_metadata'] = {
                    'analysis_type': 'ai_based',
                    'data_timestamp': datetime.now(timezone.utc).isoformat(),
                    'model_used': self.model_name,
                    'raw_data': sentiment_data
                }
                
                return result_json
            else:
                logger.error("AI ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return self.rule_based_analysis(sentiment_data)
                
        except Exception as e:
            logger.error(f"AI ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            mark_ai_api_failure()
            return self.rule_based_analysis(sentiment_data)
    
    def rule_based_analysis(self, sentiment_data: Dict) -> Dict:
        """ê·œì¹™ ê¸°ë°˜ ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„ (AI ëª¨ë¸ ì—†ì„ ë•Œ ë°±ì—…)"""
        try:
            fear_greed = sentiment_data.get('fear_greed_index', {})
            news_sentiment = sentiment_data.get('news_sentiment', {})
            
            # ê³µí¬/íƒìš• ì§€ìˆ˜ ì ìˆ˜
            fg_value = fear_greed.get('current_value', 50)
            fg_score = (fg_value - 50) / 50  # -1 ~ 1 ë²”ìœ„ë¡œ ì •ê·œí™”
            
            # ë‰´ìŠ¤ ê°ì • ì ìˆ˜
            news_score = news_sentiment.get('sentiment_score', 0)
            
            # ê°€ì¤‘í‰ê·  (ê³µí¬/íƒìš• ì§€ìˆ˜ 70%, ë‰´ìŠ¤ 30%)
            combined_score = (fg_score * 0.7) + (news_score * 0.3)
            
            # ì‹œì¥ ì‹¬ë¦¬ ì ìˆ˜ (0-100)
            market_sentiment_score = max(0, min(100, (combined_score + 1) * 50))
            
            # ì‹¬ë¦¬ ìƒíƒœ ë¶„ë¥˜
            if market_sentiment_score >= 80:
                sentiment_state = "ê·¹ë„ì˜ íƒìš•"
                market_impact = "ê³¼ì—´ ìœ„í—˜"
            elif market_sentiment_score >= 65:
                sentiment_state = "íƒìš•"
                market_impact = "ìƒìŠ¹ ëª¨ë©˜í…€"
            elif market_sentiment_score >= 35:
                sentiment_state = "ì¤‘ë¦½"
                market_impact = "í˜¼ì¡°ì„¸"
            elif market_sentiment_score >= 20:
                sentiment_state = "ê³µí¬"
                market_impact = "í•˜ë½ ì••ë ¥"
            else:
                sentiment_state = "ê·¹ë„ì˜ ê³µí¬"
                market_impact = "ë°”ë‹¥ ì‹ í˜¸ ê°€ëŠ¥ì„±"
            
            # íˆ¬ì ì‹¬ë¦¬ ì˜í–¥
            if market_sentiment_score > 60:
                investment_recommendation = "ì£¼ì˜ ê¹Šì€ ê´€ì°°"
            elif market_sentiment_score < 40:
                investment_recommendation = "ê¸°íšŒ ëª¨ìƒ‰"
            else:
                investment_recommendation = "ì¤‘ë¦½ì  ì ‘ê·¼"
            
            result = {
                "market_sentiment_score": round(market_sentiment_score, 1),
                "sentiment_state": sentiment_state,
                "market_impact": market_impact,
                "investment_recommendation": investment_recommendation,
                "fear_greed_analysis": {
                    "current_value": fg_value,
                    "classification": fear_greed.get('current_classification', 'Neutral'),
                    "trend": fear_greed.get('trend_direction', 'stable'),
                    "interpretation": self._interpret_fear_greed(fg_value)
                },
                "news_analysis": {
                    "overall_sentiment": news_sentiment.get('overall_sentiment', 'neutral'),
                    "positive_ratio": round(news_sentiment.get('positive_count', 0) / max(1, news_sentiment.get('total_news', 1)) * 100, 1),
                    "negative_ratio": round(news_sentiment.get('negative_count', 0) / max(1, news_sentiment.get('total_news', 1)) * 100, 1),
                    "total_news_analyzed": news_sentiment.get('total_news', 0)
                },
                "combined_analysis": {
                    "fear_greed_weight": 70,
                    "news_weight": 30,
                    "combined_score": round(combined_score, 3),
                    "confidence": min(90, max(40, abs(combined_score) * 80 + 40))
                },
                "confidence": min(90, max(40, abs(combined_score) * 80 + 40)),
                "analysis_summary": f"ê³µí¬/íƒìš• ì§€ìˆ˜ {fg_value}ì™€ ë‰´ìŠ¤ ê°ì •ì„ ì¢…í•©í•œ ì‹œì¥ ì‹¬ë¦¬ëŠ” '{sentiment_state}' ìƒíƒœì…ë‹ˆë‹¤."
            }
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            result['analysis_metadata'] = {
                'analysis_type': 'rule_based',
                'data_timestamp': datetime.now(timezone.utc).isoformat(),
                'model_used': 'rule_based_fallback',
                'raw_data': sentiment_data
            }
            
            return result
            
        except Exception as e:
            logger.error(f"ê·œì¹™ ê¸°ë°˜ ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "market_sentiment_score": 50,
                "sentiment_state": "ì¤‘ë¦½",
                "error": str(e),
                "confidence": 0,
                "analysis_summary": f"ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
    
    def _interpret_fear_greed(self, value: int) -> str:
        """ê³µí¬/íƒìš• ì§€ìˆ˜ í•´ì„"""
        if value >= 75:
            return "ì‹œì¥ì´ ê³¼ì—´ ìƒíƒœë¡œ ì¡°ì • ê°€ëŠ¥ì„±"
        elif value >= 55:
            return "ë‚™ê´€ì  ë¶„ìœ„ê¸°ë¡œ ìƒìŠ¹ ëª¨ë©˜í…€"
        elif value >= 45:
            return "ê· í˜• ì¡íŒ ì‹œì¥ ìƒíƒœ"
        elif value >= 25:
            return "ë¶ˆì•ˆê° í™•ì‚°ìœ¼ë¡œ í•˜ë½ ì••ë ¥"
        else:
            return "ê·¹ë„ì˜ ê³µí¬ë¡œ ë°˜ë“± ê¸°íšŒ ëª¨ìƒ‰"
    
    def _process_cached_fear_greed(self, cached_data: Dict) -> Dict:
        """ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œ ê°€ì ¸ì˜¨ ìºì‹œëœ ê³µí¬/íƒìš• ë°ì´í„° ì²˜ë¦¬"""
        try:
            if 'data' not in cached_data:
                return self._get_dummy_fear_greed()
            
            fear_greed_data = []
            for item in cached_data['data']:
                fear_greed_data.append({
                    'value': int(item['value']),
                    'classification': item['value_classification'],
                    'timestamp': item['timestamp'],
                    'date': datetime.fromtimestamp(int(item['timestamp'])).strftime('%Y-%m-%d')
                })
            
            # ìµœì‹  ë°ì´í„°ì™€ í‰ê·  ê³„ì‚°
            latest = fear_greed_data[0]
            avg_value = sum(item['value'] for item in fear_greed_data) / len(fear_greed_data)
            
            # ì¶”ì„¸ ê³„ì‚°
            if len(fear_greed_data) >= 7:
                trend = fear_greed_data[0]['value'] - fear_greed_data[6]['value']
                trend_direction = 'increasing' if trend > 5 else 'decreasing' if trend < -5 else 'stable'
            else:
                trend = 0
                trend_direction = 'stable'
            
            return {
                'current_value': latest['value'],
                'current_classification': latest['classification'],
                'week_average': round(avg_value, 1),
                'trend_change': trend,
                'trend_direction': trend_direction,
                'historical_data': fear_greed_data,
                'market_sentiment': self._classify_market_sentiment(latest['value']),
                'cached': True
            }
            
        except Exception as e:
            logger.error(f"ìºì‹œëœ ê³µí¬/íƒìš• ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return self._get_dummy_fear_greed()
    
    def check_data_availability(self) -> bool:
        """ë°ì´í„° ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        if (self.error_counts['fear_greed'] >= self.max_errors and 
            self.error_counts['news'] >= self.max_errors):
            return False
        return True
    
    async def analyze_market_sentiment(self) -> Dict:
        """ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜ - ìˆ˜ì •ëœ ë²„ì „ (ìˆœí™˜ import í•´ê²°)"""
        try:
            logger.info("ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„ ì‹œì‘")
            
            # ë°ì´í„° ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            if not self.check_data_availability():
                logger.warning("ì‹¬ë¦¬ ë¶„ì„: ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ ì‹¤íŒ¨ - ë¶„ì„ ê±´ë„ˆë›°ê¸°")
                return {
                    "success": False,
                    "error": "ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì—°ì† ì‹¤íŒ¨ - ë¶„ì„ ë¶ˆê°€",
                    "analysis_type": "market_sentiment",
                    "skip_reason": "insufficient_data"
                }
            
            # ğŸ”§ ìˆ˜ì •: ìŠ¤ì¼€ì¤„ëŸ¬ ì‚¬ìš© ëŒ€ì‹  ì§ì ‘ MongoDBì—ì„œ ìºì‹œ ì¡°íšŒ + ì§ì ‘ ìˆ˜ì§‘
            
            # 1. ê³µí¬/íƒìš• ì§€ìˆ˜ - ìºì‹œëœ ë°ì´í„° ìš°ì„  ì‚¬ìš©
            fear_greed_data = self._get_cached_fear_greed()
            if fear_greed_data is None:
                # ìºì‹œì— ì—†ìœ¼ë©´ ì§ì ‘ ìˆ˜ì§‘
                fear_greed_data = self.get_fear_greed_index()
            
            # 2. ë‰´ìŠ¤ ë°ì´í„° - ìºì‹œëœ ë°ì´í„° ìš°ì„  ì‚¬ìš©  
            recent_news = self._get_cached_news()
            if recent_news is None:
                # ìºì‹œì— ì—†ìœ¼ë©´ ì§ì ‘ ìˆ˜ì§‘
                recent_news = self.get_crypto_news()
            
            # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
            if fear_greed_data is None and (recent_news is None or len(recent_news) == 0):
                logger.warning("ì‹¬ë¦¬ ë¶„ì„: ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì—†ìŒ")
                return {
                    "success": False,
                    "error": "ìœ íš¨í•œ ë°ì´í„° ì—†ìŒ - ë¶„ì„ ë¶ˆê°€",
                    "analysis_type": "market_sentiment",
                    "skip_reason": "no_valid_data"
                }
            
            # 3. ë‰´ìŠ¤ ê°ì • ë¶„ì„
            news_sentiment = self.analyze_news_sentiment(recent_news or [])
            
            # 4. ë°ì´í„° í†µí•©
            sentiment_data = {
                'fear_greed_index': fear_greed_data,
                'news_sentiment': news_sentiment,
                'recent_news': recent_news or [],
                'data_collection_time': datetime.now(timezone.utc).isoformat(),
                'data_quality': {
                    'fear_greed_available': fear_greed_data is not None,
                    'news_available': recent_news is not None and len(recent_news) > 0,
                    'error_counts': self.error_counts.copy()
                }
            }
            
            # 5. AI ì¢…í•© ë¶„ì„
            analysis_result = await self.analyze_with_ai(sentiment_data)
            
            logger.info("ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„ ì™„ë£Œ")
            
            return {
                "success": True,
                "result": analysis_result,
                "analysis_type": "market_sentiment"
            }
            
        except Exception as e:
            logger.error(f"ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "analysis_type": "market_sentiment"
            }

# ì™¸ë¶€ì—ì„œ ì‚¬ìš©í•  í•¨ìˆ˜
async def analyze_market_sentiment() -> Dict:
    """ì‹œì¥ ì‹¬ë¦¬ë¥¼ ë¶„ì„í•˜ëŠ” í•¨ìˆ˜"""
    analyzer = SentimentAnalyzer()
    return await analyzer.analyze_market_sentiment()

# í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
if __name__ == "__main__":
    import asyncio
    
    async def test():
        result = await analyze_market_sentiment()
        print(json.dumps(result, indent=2, ensure_ascii=False))
    
    asyncio.run(test())