"""
AI íˆ¬ì ì‹œìŠ¤í…œìš© ë°ì´í„° ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ëŸ¬
ê° ë°ì´í„° ì†ŒìŠ¤ë³„ë¡œ ìµœì í™”ëœ ìˆ˜ì§‘ ì£¼ê¸° ê´€ë¦¬
"""

import asyncio
import time
import logging
from datetime import datetime, timezone, timedelta
from typing import Dict, Optional, Callable, Any
from dataclasses import dataclass
import json

logger = logging.getLogger("data_scheduler")

@dataclass
class DataTask:
    """ë°ì´í„° ìˆ˜ì§‘ ì‘ì—… ì •ì˜"""
    name: str
    func: Callable
    interval_minutes: int
    last_run: Optional[datetime] = None
    data_cache: Any = None
    cache_duration_minutes: int = 0  # 0ì´ë©´ ìºì‹œ ì‚¬ìš© ì•ˆí•¨
    is_running: bool = False
    error_count: int = 0
    max_errors: int = 3

class DataScheduler:
    """ë°ì´í„° ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ëŸ¬"""
    
    def __init__(self, main_interval_minutes: int = 15):
        self.main_interval = main_interval_minutes
        self.tasks: Dict[str, DataTask] = {}
        self.running = False
        
        # ê¸°ë³¸ ë°ì´í„° ìˆ˜ì§‘ ì‘ì—…ë“¤ ë“±ë¡
        self._register_default_tasks()
    
    def _register_default_tasks(self):
        """ê¸°ë³¸ ë°ì´í„° ìˆ˜ì§‘ ì‘ì—…ë“¤ ë“±ë¡"""
        
        # 1. ì°¨íŠ¸ ë°ì´í„° - 15ë¶„ë§ˆë‹¤ (ë©”ì¸ ì£¼ê¸°ì™€ ë™ì¼)
        self.register_task(
            name="chart_data",
            func=self._collect_chart_data,
            interval_minutes=15,
            cache_duration_minutes=5  # 5ë¶„ê°„ ìºì‹œ
        )
        
        # 2. ê³µí¬/íƒìš• ì§€ìˆ˜ - 4ì‹œê°„ë§ˆë‹¤ (í•˜ë£¨ 6ë²ˆ)
        self.register_task(
            name="fear_greed_index",
            func=self._collect_fear_greed_data,
            interval_minutes=240,  # 4ì‹œê°„
            cache_duration_minutes=120  # 2ì‹œê°„ ìºì‹œ
        )
        
        # 3. ë‰´ìŠ¤ ë°ì´í„° - 30ë¶„ë§ˆë‹¤
        self.register_task(
            name="crypto_news",
            func=self._collect_news_data,
            interval_minutes=30,
            cache_duration_minutes=15  # 15ë¶„ ìºì‹œ
        )
        
        # 4. ê±°ì‹œê²½ì œ ë°ì´í„° - 6ì‹œê°„ë§ˆë‹¤ (í•˜ë£¨ 4ë²ˆ)
        self.register_task(
            name="macro_economic",
            func=self._collect_macro_data,
            interval_minutes=360,  # 6ì‹œê°„
            cache_duration_minutes=180  # 3ì‹œê°„ ìºì‹œ
        )
        
        # 5. ì˜¨ì²´ì¸ ë°ì´í„° - 1ì‹œê°„ë§ˆë‹¤
        self.register_task(
            name="onchain_data",
            func=self._collect_onchain_data,
            interval_minutes=60,
            cache_duration_minutes=30  # 30ë¶„ ìºì‹œ
        )
        
        # 6. ê¸°ê´€ íˆ¬ì ë°ì´í„° - 2ì‹œê°„ë§ˆë‹¤
        self.register_task(
            name="institutional_data",
            func=self._collect_institutional_data,
            interval_minutes=120,
            cache_duration_minutes=60  # 1ì‹œê°„ ìºì‹œ
        )
        
        # 7. í¬ì§€ì…˜/ì”ê³  ë°ì´í„° - ì‹¤ì‹œê°„ (ìºì‹œ ì—†ìŒ)
        self.register_task(
            name="position_data",
            func=self._collect_position_data,
            interval_minutes=0,  # í•­ìƒ ì‹¤ì‹œê°„
            cache_duration_minutes=0  # ìºì‹œ ì—†ìŒ
        )
    
    def register_task(self, name: str, func: Callable, interval_minutes: int, 
                     cache_duration_minutes: int = 0):
        """ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘ ì‘ì—… ë“±ë¡"""
        self.tasks[name] = DataTask(
            name=name,
            func=func,
            interval_minutes=interval_minutes,
            cache_duration_minutes=cache_duration_minutes
        )
        logger.info(f"ë°ì´í„° ì‘ì—… ë“±ë¡: {name} (ìˆ˜ì§‘ì£¼ê¸°: {interval_minutes}ë¶„, ìºì‹œ: {cache_duration_minutes}ë¶„)")
    
    def should_run_task(self, task: DataTask) -> bool:
        """ì‘ì—… ì‹¤í–‰ ì—¬ë¶€ íŒë‹¨"""
        if task.is_running:
            return False
        
        # ì‹¤ì‹œê°„ ë°ì´í„°ëŠ” í•­ìƒ ì‹¤í–‰
        if task.interval_minutes == 0:
            return True
        
        # ì²« ì‹¤í–‰
        if task.last_run is None:
            return True
        
        # ì£¼ê¸° í™•ì¸
        time_since_last = datetime.now(timezone.utc) - task.last_run
        return time_since_last.total_seconds() >= task.interval_minutes * 60
    
    def get_cached_data(self, task_name: str) -> Optional[Any]:
        """ìºì‹œëœ ë°ì´í„° ë°˜í™˜"""
        if task_name not in self.tasks:
            return None
        
        task = self.tasks[task_name]
        
        # ìºì‹œê°€ ì—†ê±°ë‚˜ ë§Œë£Œëœ ê²½ìš°
        if (task.cache_duration_minutes == 0 or 
            task.data_cache is None or 
            task.last_run is None):
            return None
        
        # ìºì‹œ ë§Œë£Œ í™•ì¸
        cache_age = datetime.now(timezone.utc) - task.last_run
        if cache_age.total_seconds() > task.cache_duration_minutes * 60:
            return None
        
        logger.debug(f"ìºì‹œëœ ë°ì´í„° ì‚¬ìš©: {task_name}")
        return task.data_cache
    
    async def run_task(self, task: DataTask) -> Optional[Any]:
        """ê°œë³„ ì‘ì—… ì‹¤í–‰"""
        try:
            task.is_running = True
            logger.debug(f"ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {task.name}")
            
            start_time = datetime.now()
            result = await task.func()
            end_time = datetime.now()
            
            duration = (end_time - start_time).total_seconds()
            
            # ì„±ê³µ ì‹œ ìºì‹œ ì—…ë°ì´íŠ¸
            if result is not None:
                task.data_cache = result
                task.last_run = datetime.now(timezone.utc)
                task.error_count = 0  # ì—ëŸ¬ ì¹´ìš´íŠ¸ ë¦¬ì…‹
                logger.debug(f"ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {task.name} ({duration:.2f}ì´ˆ)")
            else:
                task.error_count += 1
                logger.warning(f"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {task.name} (ì˜¤ë¥˜ {task.error_count}/{task.max_errors})")
            
            return result
            
        except Exception as e:
            task.error_count += 1
            logger.error(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {task.name} - {str(e)}")
            return None
        finally:
            task.is_running = False
    
    async def get_data(self, task_name: str) -> Optional[Any]:
        """ë°ì´í„° ìš”ì²­ (ìºì‹œ ìš°ì„ , í•„ìš”ì‹œ ìˆ˜ì§‘)"""
        if task_name not in self.tasks:
            logger.error(f"ë“±ë¡ë˜ì§€ ì•Šì€ ë°ì´í„° ì‘ì—…: {task_name}")
            return None
        
        task = self.tasks[task_name]
        
        # ì—ëŸ¬ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ìŠ¤í‚µ
        if task.error_count >= task.max_errors:
            logger.warning(f"ë°ì´í„° ì‘ì—… ìŠ¤í‚µ (ìµœëŒ€ ì˜¤ë¥˜ íšŸìˆ˜ ì´ˆê³¼): {task_name}")
            return task.data_cache  # ë§ˆì§€ë§‰ ì„±ê³µ ë°ì´í„°ë¼ë„ ë°˜í™˜
        
        # ìºì‹œëœ ë°ì´í„° í™•ì¸
        cached_data = self.get_cached_data(task_name)
        if cached_data is not None:
            return cached_data
        
        # ìˆ˜ì§‘ í•„ìš” ì—¬ë¶€ í™•ì¸
        if self.should_run_task(task):
            return await self.run_task(task)
        else:
            # ìˆ˜ì§‘ ì£¼ê¸°ê°€ ì•„ë‹ˆë©´ ë§ˆì§€ë§‰ ë°ì´í„° ë°˜í™˜
            return task.data_cache
    
    async def run_scheduled_collections(self):
        """ì˜ˆì •ëœ ìˆ˜ì§‘ ì‘ì—…ë“¤ ì‹¤í–‰"""
        logger.info("ì˜ˆì •ëœ ë°ì´í„° ìˆ˜ì§‘ ì‘ì—… ì‹¤í–‰")
        
        tasks_to_run = []
        for task_name, task in self.tasks.items():
            if self.should_run_task(task) and task.interval_minutes > 0:
                tasks_to_run.append((task_name, task))
        
        if not tasks_to_run:
            logger.debug("ì‹¤í–‰í•  ì˜ˆì • ì‘ì—… ì—†ìŒ")
            return
        
        logger.info(f"ì‹¤í–‰í•  ì‘ì—…: {[name for name, _ in tasks_to_run]}")
        
        # ë³‘ë ¬ ì‹¤í–‰
        await asyncio.gather(*[self.run_task(task) for _, task in tasks_to_run])
    
    def get_task_status(self) -> Dict:
        """ëª¨ë“  ì‘ì—…ì˜ ìƒíƒœ ë°˜í™˜"""
        status = {}
        for task_name, task in self.tasks.items():
            status[task_name] = {
                'interval_minutes': task.interval_minutes,
                'last_run': task.last_run.isoformat() if task.last_run else None,
                'has_cache': task.data_cache is not None,
                'is_running': task.is_running,
                'error_count': task.error_count,
                'cache_age_minutes': 0
            }
            
            # ìºì‹œ ë‚˜ì´ ê³„ì‚°
            if task.last_run:
                cache_age = datetime.now(timezone.utc) - task.last_run
                status[task_name]['cache_age_minutes'] = cache_age.total_seconds() / 60
        
        return status
    
    # ============= ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ë“¤ =============
    
    async def _collect_chart_data(self):
        """ì°¨íŠ¸ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            # ê¸°ì¡´ ì°¨íŠ¸ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ ì‚¬ìš©
            from docs.get_chart import chart_update_one
            result, server_time, execution_time = chart_update_one('15m', 'BTCUSDT')
            return {
                'success': result is not None,
                'server_time': server_time,
                'execution_time': execution_time,
                'timestamp': datetime.now(timezone.utc).isoformat()
            }
        except Exception as e:
            logger.error(f"ì°¨íŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return None
    
    async def _collect_fear_greed_data(self):
        """ê³µí¬/íƒìš• ì§€ìˆ˜ ìˆ˜ì§‘"""
        try:
            import requests
            response = requests.get("https://api.alternative.me/fng/?limit=7", timeout=10)
            if response.status_code == 200:
                data = response.json()
                return {
                    'data': data,
                    'timestamp': datetime.now(timezone.utc).isoformat()
                }
        except Exception as e:
            logger.error(f"ê³µí¬/íƒìš• ì§€ìˆ˜ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        return None
    
    async def _collect_news_data(self):
        """ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            import feedparser
            
            news_sources = {
                'cointelegraph': 'https://cointelegraph.com/rss',
                'coindesk': 'https://www.coindesk.com/arc/outboundfeeds/rss/',
            }
            
            all_news = []
            for source_name, rss_url in news_sources.items():
                try:
                    feed = feedparser.parse(rss_url)
                    for entry in feed.entries[:5]:  # ìµœì‹  5ê°œë§Œ
                        title = entry.get('title', '').lower()
                        if any(keyword in title for keyword in ['bitcoin', 'btc', 'crypto']):
                            all_news.append({
                                'title': entry.get('title', ''),
                                'summary': entry.get('summary', '')[:200],
                                'source': source_name,
                                'published_time': getattr(entry, 'published', ''),
                                'link': entry.get('link', '')
                            })
                except Exception as e:
                    logger.warning(f"{source_name} ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            
            return {
                'news': all_news,
                'count': len(all_news),
                'timestamp': datetime.now(timezone.utc).isoformat()
            }
        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        return None
    
    async def _collect_macro_data(self):
        """ê±°ì‹œê²½ì œ ë°ì´í„° ìˆ˜ì§‘ (ë”ë¯¸ ë°ì´í„°)"""
        # ì‹¤ì œë¡œëŠ” ê²½ì œ ì§€í‘œ APIë¥¼ í˜¸ì¶œí•´ì•¼ í•¨
        return {
            'indicators': {
                'dxy': 103.5,  # ë‹¬ëŸ¬ì§€ìˆ˜
                'gold': 2650,  # ê¸ˆ ê°€ê²©
                'sp500': 4500,  # S&P 500
                'interest_rate': 5.25  # ê¸°ì¤€ê¸ˆë¦¬
            },
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
    
    async def _collect_onchain_data(self):
        """ì˜¨ì²´ì¸ ë°ì´í„° ìˆ˜ì§‘ (ë”ë¯¸ ë°ì´í„°)"""
        # ì‹¤ì œë¡œëŠ” ì˜¨ì²´ì¸ ë¶„ì„ APIë¥¼ í˜¸ì¶œí•´ì•¼ í•¨
        return {
            'metrics': {
                'hash_rate': 450000000,  # TH/s
                'difficulty': 72000000000000,
                'active_addresses': 980000,
                'transaction_count': 350000
            },
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
    
    async def _collect_institutional_data(self):
        """ê¸°ê´€ íˆ¬ì ë°ì´í„° ìˆ˜ì§‘ (ë”ë¯¸ ë°ì´í„°)"""
        # ì‹¤ì œë¡œëŠ” ê¸°ê´€ íˆ¬ì ê´€ë ¨ APIë¥¼ í˜¸ì¶œí•´ì•¼ í•¨
        return {
            'flows': {
                'etf_inflow': 150000000,  # ë‹¬ëŸ¬
                'institutional_holdings': 800000,  # BTC
                'corporate_treasury': 250000  # BTC
            },
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
    
    async def _collect_position_data(self):
        """í¬ì§€ì…˜/ì”ê³  ë°ì´í„° ìˆ˜ì§‘"""
        try:
            from docs.get_current import fetch_investment_status
            balance, positions_json, ledger = fetch_investment_status()
            
            if balance == 'error':
                return None
            
            return {
                'balance': balance,
                'positions': positions_json,
                'ledger': ledger[:10] if ledger else [],  # ìµœê·¼ 10ê°œë§Œ
                'timestamp': datetime.now(timezone.utc).isoformat()
            }
        except Exception as e:
            logger.error(f"í¬ì§€ì…˜ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        return None

# ì „ì—­ ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
_global_scheduler: Optional[DataScheduler] = None

def get_data_scheduler() -> DataScheduler:
    """ì „ì—­ ë°ì´í„° ìŠ¤ì¼€ì¤„ëŸ¬ ë°˜í™˜"""
    global _global_scheduler
    if _global_scheduler is None:
        _global_scheduler = DataScheduler()
    return _global_scheduler

# í¸ì˜ í•¨ìˆ˜ë“¤
async def get_chart_data():
    """ì°¨íŠ¸ ë°ì´í„° ìš”ì²­"""
    scheduler = get_data_scheduler()
    return await scheduler.get_data("chart_data")

async def get_fear_greed_data():
    """ê³µí¬/íƒìš• ì§€ìˆ˜ ìš”ì²­"""
    scheduler = get_data_scheduler()
    return await scheduler.get_data("fear_greed_index")

async def get_news_data():
    """ë‰´ìŠ¤ ë°ì´í„° ìš”ì²­"""
    scheduler = get_data_scheduler()
    return await scheduler.get_data("crypto_news")

async def get_macro_data():
    """ê±°ì‹œê²½ì œ ë°ì´í„° ìš”ì²­"""
    scheduler = get_data_scheduler()
    return await scheduler.get_data("macro_economic")

async def get_onchain_data():
    """ì˜¨ì²´ì¸ ë°ì´í„° ìš”ì²­"""
    scheduler = get_data_scheduler()
    return await scheduler.get_data("onchain_data")

async def get_institutional_data():
    """ê¸°ê´€ íˆ¬ì ë°ì´í„° ìš”ì²­"""
    scheduler = get_data_scheduler()
    return await scheduler.get_data("institutional_data")

async def get_position_data():
    """í¬ì§€ì…˜ ë°ì´í„° ìš”ì²­"""
    scheduler = get_data_scheduler()
    return await scheduler.get_data("position_data")

async def run_scheduled_data_collection():
    """ì˜ˆì •ëœ ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰"""
    scheduler = get_data_scheduler()
    await scheduler.run_scheduled_collections()

def get_data_status():
    """ë°ì´í„° ìˆ˜ì§‘ ìƒíƒœ í™•ì¸"""
    scheduler = get_data_scheduler()
    return scheduler.get_task_status()

# í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
if __name__ == "__main__":
    async def test():
        print("ğŸ“Š ë°ì´í„° ìŠ¤ì¼€ì¤„ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        scheduler = get_data_scheduler()
        
        # ìƒíƒœ í™•ì¸
        print("\n=== ì´ˆê¸° ìƒíƒœ ===")
        status = scheduler.get_task_status()
        for task_name, info in status.items():
            print(f"{task_name}: ì£¼ê¸° {info['interval_minutes']}ë¶„, ìºì‹œ {info['cache_age_minutes']:.1f}ë¶„")
        
        # ì°¨íŠ¸ ë°ì´í„° í…ŒìŠ¤íŠ¸
        print("\n=== ì°¨íŠ¸ ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ===")
        chart_data = await get_chart_data()
        print(f"ì°¨íŠ¸ ë°ì´í„°: {chart_data is not None}")
        
        # ê³µí¬/íƒìš• ì§€ìˆ˜ í…ŒìŠ¤íŠ¸
        print("\n=== ê³µí¬/íƒìš• ì§€ìˆ˜ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ===")
        fg_data = await get_fear_greed_data()
        print(f"ê³µí¬/íƒìš• ë°ì´í„°: {fg_data is not None}")
        
        # ì˜ˆì •ëœ ìˆ˜ì§‘ ì‹¤í–‰
        print("\n=== ì˜ˆì •ëœ ìˆ˜ì§‘ ì‹¤í–‰ ===")
        await run_scheduled_data_collection()
        
        # ìµœì¢… ìƒíƒœ
        print("\n=== ìµœì¢… ìƒíƒœ ===")
        final_status = get_data_status()
        for task_name, info in final_status.items():
            cache_status = "ìºì‹œë¨" if info['has_cache'] else "ì—†ìŒ"
            print(f"{task_name}: {cache_status}, ì˜¤ë¥˜ {info['error_count']}íšŒ")
    
    asyncio.run(test())