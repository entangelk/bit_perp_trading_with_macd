# data_scheduler.py - ì§ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ë¡œ í¬ì›Œë”©

"""
ê¸°ì¡´ ìºì‹œ ê¸°ë°˜ ë³µì¡í•œ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì§ë ¬ ì¹´ìš´íŒ… ìŠ¤ì¼€ì¤„ëŸ¬ë¡œ êµì²´
ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´ í¬ì›Œë”© í•¨ìˆ˜ë“¤ ì œê³µ
"""

from docs.investment_ai.serial_scheduler import (
    get_serial_scheduler, 
    run_serial_cycle,
    get_serial_data,
    get_serial_status,
    get_final_decision
)
import logging

logger = logging.getLogger("data_scheduler")

# ========= ğŸ”§ ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜ë˜ë„ë¡ í¬ì›Œë”© í•¨ìˆ˜ë“¤ =========

def get_data_scheduler():
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í¬ì›Œë”© - ì§ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ ë°˜í™˜"""
    return get_serial_scheduler()

async def run_scheduled_data_collection(initial_run=False):
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í¬ì›Œë”© - ì§ë ¬ ì‚¬ì´í´ ì‹¤í–‰"""
    logger.info("ìŠ¤ì¼€ì¤„ë§ëœ ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰ (ì§ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ë¡œ í¬ì›Œë”©)")
    return await run_serial_cycle()

def get_data_status():
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í¬ì›Œë”© - ì§ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ"""
    return get_serial_status()

# ========= ê°œë³„ ë°ì´í„° ìš”ì²­ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ í˜¸í™˜ì„±) =========

async def get_chart_data():
    """ì°¨íŠ¸ ë°ì´í„° ìš”ì²­ - ì§ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œ chart_update ê²°ê³¼"""
    return get_serial_data("chart_update")

async def get_fear_greed_data():
    """ê³µí¬/íƒìš• ì§€ìˆ˜ ìš”ì²­ - ê°ì •ë¶„ì„ ê²°ê³¼ì— í¬í•¨"""
    sentiment_result = get_serial_data("ai_sentiment_analysis")
    if sentiment_result and isinstance(sentiment_result, dict):
        # ê°ì • ë¶„ì„ ê²°ê³¼ì—ì„œ ê³µí¬íƒìš• ì§€ìˆ˜ ì¶”ì¶œ
        return {
            'current_fng': sentiment_result.get('fear_greed_index', 50),
            'timestamp': sentiment_result.get('analysis_timestamp', 'unknown')
        }
    return None

async def get_news_data():
    """ë‰´ìŠ¤ ë°ì´í„° ìš”ì²­ - ê°ì •ë¶„ì„ ê²°ê³¼ì— í¬í•¨"""
    sentiment_result = get_serial_data("ai_sentiment_analysis") 
    if sentiment_result and isinstance(sentiment_result, dict):
        # ê°ì • ë¶„ì„ ê²°ê³¼ì—ì„œ ë‰´ìŠ¤ ë°ì´í„° ì¶”ì¶œ
        return {
            'news': sentiment_result.get('news_summary', []),
            'count': len(sentiment_result.get('news_summary', [])),
            'timestamp': sentiment_result.get('analysis_timestamp', 'unknown')
        }
    return None

async def get_macro_data():
    """ê±°ì‹œê²½ì œ ë°ì´í„° ìš”ì²­"""
    return get_serial_data("ai_macro_analysis")

async def get_onchain_data():
    """ì˜¨ì²´ì¸ ë°ì´í„° ìš”ì²­"""
    return get_serial_data("ai_onchain_analysis")

async def get_institutional_data():
    """ê¸°ê´€íˆ¬ì ë°ì´í„° ìš”ì²­"""
    return get_serial_data("ai_institutional_analysis")

async def get_position_data():
    """í¬ì§€ì…˜ ë°ì´í„° ìš”ì²­"""
    return get_serial_data("position_data")

# ========= AI ë¶„ì„ ê²°ê³¼ ìš”ì²­ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ í˜¸í™˜ì„±) =========

async def get_ai_sentiment_analysis():
    """AI ì‹œì¥ ê°ì • ë¶„ì„ ê²°ê³¼ ìš”ì²­"""
    return get_serial_data("ai_sentiment_analysis")

async def get_ai_technical_analysis():
    """AI ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ ìš”ì²­"""
    return get_serial_data("ai_technical_analysis")

async def get_ai_macro_analysis():
    """AI ê±°ì‹œê²½ì œ ë¶„ì„ ê²°ê³¼ ìš”ì²­"""
    return get_serial_data("ai_macro_analysis")

async def get_ai_onchain_analysis():
    """AI ì˜¨ì²´ì¸ ë¶„ì„ ê²°ê³¼ ìš”ì²­"""
    return get_serial_data("ai_onchain_analysis")

async def get_ai_institutional_analysis():
    """AI ê¸°ê´€íˆ¬ì ë¶„ì„ ê²°ê³¼ ìš”ì²­"""
    return get_serial_data("ai_institutional_analysis")

# ========= ê¸°íƒ€ í˜¸í™˜ì„± í•¨ìˆ˜ë“¤ =========

def get_recovery_status():
    """ë³µêµ¬ ìƒíƒœ - ì§ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œëŠ” ë‹¨ìˆœí™”"""
    status = get_serial_status()
    
    disabled_tasks = []
    healthy_tasks = []
    
    for task_name, task_info in status.get('tasks', {}).items():
        if task_info.get('is_disabled', False):
            disabled_tasks.append(task_name)
        else:
            healthy_tasks.append(task_name)
    
    return {
        'disabled_tasks': disabled_tasks,
        'recovering_tasks': [],  # ì§ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œëŠ” ìë™ ë³µêµ¬ ì—†ìŒ
        'healthy_tasks': healthy_tasks,
        'next_recovery_times': {}
    }

def force_recovery(task_name: str = None):
    """ê°•ì œ ë³µêµ¬ - ì—ëŸ¬ ì¹´ìš´íŠ¸ ë¦¬ì…‹"""
    scheduler = get_serial_scheduler()
    scheduler.reset_errors(task_name)
    return True

def reset_errors(task_name: str = None):
    """ì—ëŸ¬ ì¹´ìš´íŠ¸ ë¦¬ì…‹"""
    scheduler = get_serial_scheduler()
    scheduler.reset_errors(task_name)
    return True

# ========= AI API ìƒíƒœ ê´€ë¦¬ (ê¸°ì¡´ í˜¸í™˜ì„± - ë‹¨ìˆœí™”) =========

_ai_api_status = {
    'is_working': True,
    'last_success_time': None,
    'last_failure_time': None,
    'consecutive_failures': 0,
    'last_check_time': None
}

def check_ai_api_status():
    """AI API ìƒíƒœ í™•ì¸"""
    return _ai_api_status.copy()

def mark_ai_api_success():
    """AI API ì„±ê³µ ì‹œ í˜¸ì¶œ"""
    global _ai_api_status
    import datetime
    _ai_api_status.update({
        'is_working': True,
        'last_success_time': datetime.datetime.now(),
        'consecutive_failures': 0,
        'last_check_time': datetime.datetime.now()
    })
    logger.info("AI API ì‘ë™ ìƒíƒœ: ì •ìƒ")

def mark_ai_api_failure():
    """AI API ì‹¤íŒ¨ ì‹œ í˜¸ì¶œ"""
    global _ai_api_status
    import datetime
    _ai_api_status.update({
        'last_failure_time': datetime.datetime.now(),
        'consecutive_failures': _ai_api_status['consecutive_failures'] + 1,
        'last_check_time': datetime.datetime.now()
    })
    
    if _ai_api_status['consecutive_failures'] >= 3:
        _ai_api_status['is_working'] = False
        logger.error(f"AI API ë¹„ì‘ë™ ìƒíƒœ: {_ai_api_status['consecutive_failures']}íšŒ ì—°ì† ì‹¤íŒ¨")
    else:
        logger.warning(f"AI API ì‹¤íŒ¨: {_ai_api_status['consecutive_failures']}/3íšŒ")

async def test_ai_api_connection():
    """AI API ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        # ê°„ë‹¨í•œ ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸
        from docs.investment_ai.analyzers.sentiment_analyzer import SentimentAnalyzer
        analyzer = SentimentAnalyzer()
        
        if analyzer.client is None:
            mark_ai_api_failure()
            return False
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
        test_prompt = "Hello, respond with just 'OK'"
        response = analyzer.client.models.generate_content("gemini-1.5-flash", test_prompt)
        
        if response and response.text:
            mark_ai_api_success()
            return True
        else:
            mark_ai_api_failure()
            return False
            
    except Exception as e:
        logger.error(f"AI API ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        mark_ai_api_failure()
        return False

def get_ai_api_status_summary():
    """AI API ìƒíƒœ ìš”ì•½ ì •ë³´"""
    status = check_ai_api_status()
    return {
        'is_working': status['is_working'],
        'consecutive_failures': status['consecutive_failures'],
        'last_success': status['last_success_time'].isoformat() if status['last_success_time'] else None,
        'last_failure': status['last_failure_time'].isoformat() if status['last_failure_time'] else None,
        'status_text': 'AI API ì •ìƒ ì‘ë™' if status['is_working'] else f'AI API ë¹„ì‘ë™ ({status["consecutive_failures"]}íšŒ ì‹¤íŒ¨)'
    }

# ========= ìŠ¤ì¼€ì¤„ëŸ¬ í´ë˜ìŠ¤ í¬ì›Œë”© (ai_trading_integration.py í˜¸í™˜ìš©) =========

class DataScheduler:
    """ê¸°ì¡´ ìŠ¤ì¼€ì¤„ëŸ¬ í´ë˜ìŠ¤ í˜¸í™˜ì„ ìœ„í•œ í¬ì›Œë”© ë˜í¼"""
    
    def __init__(self):
        self._serial_scheduler = get_serial_scheduler()
    
    def get_cached_data(self, task_name: str):
        """ìºì‹œëœ ë°ì´í„° ì¡°íšŒ - ì§ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ì˜ ë§ˆì§€ë§‰ ê²°ê³¼ ë°˜í™˜"""
        return self._serial_scheduler.get_data(task_name)
    
    async def get_data(self, task_name: str):
        """ë°ì´í„° ìš”ì²­ - ë¹„ë™ê¸° ë²„ì „"""
        return self._serial_scheduler.get_data(task_name)
    
    def get_task_status(self):
        """ì‘ì—… ìƒíƒœ ë°˜í™˜"""
        return self._serial_scheduler.get_status()

# ì „ì—­ ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ (ê¸°ì¡´ í˜¸í™˜ì„±)
_global_scheduler = None

def get_data_scheduler():
    """ì „ì—­ ë°ì´í„° ìŠ¤ì¼€ì¤„ëŸ¬ ë°˜í™˜ - í¬ì›Œë”©"""
    global _global_scheduler
    if _global_scheduler is None:
        _global_scheduler = DataScheduler()
    return _global_scheduler

logger.info("ë°ì´í„° ìŠ¤ì¼€ì¤„ëŸ¬: ì§ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ë¡œ í¬ì›Œë”© ì„¤ì • ì™„ë£Œ")