from fastapi import APIRouter, Request, Query, HTTPException
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from typing import Optional, List, Dict, Any
from datetime import datetime, timezone, timedelta
from pymongo import MongoClient
import json
import logging
from docs.investment_ai.data_scheduler import get_data_status, get_recovery_status, get_ai_api_status_summary

logger = logging.getLogger(__name__)

router = APIRouter()
templates = Jinja2Templates(directory="/app/trading_bot/templates")

class AIAnalysisViewer:
    """AI ë¶„ì„ ê²°ê³¼ ì¡°íšŒ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.client = MongoClient("mongodb://mongodb:27017")
        self.database = self.client["bitcoin"]
        self.cache_collection = self.database["data_cache"]
    
    def get_analysis_tasks(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ AI ë¶„ì„ ì‘ì—… ëª©ë¡ ë°˜í™˜"""
        return [
            "ai_sentiment_analysis",
            "ai_technical_analysis", 
            "ai_macro_analysis",
            "ai_onchain_analysis",
            "ai_institutional_analysis",
            "final_decision"
        ]

    def sort_by_latest_first(self, analyses: List[Dict]) -> List[Dict]:
        """ë¶„ì„ê¸°ë³„ ìµœì‹  ë°ì´í„°ë¥¼ ë§¨ ìœ„ë¡œ ì´ë™"""
        if not analyses:
            return analyses
        
        # ê° ë¶„ì„ê¸°ë³„ ìµœì‹  ë°ì´í„° ì°¾ê¸°
        latest_by_task = {}
        other_analyses = []
        
        for analysis in analyses:
            task_name = analysis.get('task_name')
            if task_name not in latest_by_task:
                # ì²« ë²ˆì§¸ë¡œ ë°œê²¬ëœ ê²ƒì´ ìµœì‹  (ì´ë¯¸ ì‹œê°„ìˆœ ì—­ìˆœ ì •ë ¬ë˜ì–´ ìˆìŒ)
                latest_by_task[task_name] = analysis
            else:
                # ìµœì‹ ì´ ì•„ë‹Œ ë‚˜ë¨¸ì§€ë“¤
                other_analyses.append(analysis)
        
        # ìµœì‹  ë°ì´í„°ë“¤ì„ ë§¨ ìœ„ë¡œ, ë‚˜ë¨¸ì§€ëŠ” ì‹œê°„ìˆœìœ¼ë¡œ ìœ ì§€
        latest_analyses = list(latest_by_task.values())
        # ìµœì‹  ë°ì´í„°ë“¤ë„ ì‹œê°„ìˆœ ì •ë ¬
        latest_analyses.sort(key=lambda x: x.get('created_at', datetime.min), reverse=True)
        
        return latest_analyses + other_analyses

    def get_task_display_name(self, task_name: str) -> str:
        """ì‘ì—…ëª…ì„ í‘œì‹œìš© ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
        name_mapping = {
            "ai_sentiment_analysis": "ì‹œì¥ ê°ì • ë¶„ì„",
            "ai_technical_analysis": "ê¸°ìˆ ì  ë¶„ì„",
            "ai_macro_analysis": "ê±°ì‹œê²½ì œ ë¶„ì„", 
            "ai_onchain_analysis": "ì˜¨ì²´ì¸ ë¶„ì„",
            "ai_institutional_analysis": "ê¸°ê´€íˆ¬ì ë¶„ì„",
            "final_decision": "ìµœì¢… AI íˆ¬ì ê²°ì •"
        }
        return name_mapping.get(task_name, task_name)
    
    def get_recent_analyses(self, task_name: Optional[str] = None, hours: int = 24, limit: int = 50) -> List[Dict]:
        """ìµœê·¼ AI ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        try:
            # ì‹œê°„ ë²”ìœ„ ì„¤ì •
            since_time = datetime.now(timezone.utc) - timedelta(hours=hours)
            
            # ì¿¼ë¦¬ ì¡°ê±´ êµ¬ì„±
            query = {
                "created_at": {"$gte": since_time}
            }
            
            if task_name:
                query["task_name"] = task_name
            else:
                # AI ë¶„ì„ ì‘ì—…ë§Œ ì¡°íšŒ
                query["task_name"] = {"$in": self.get_analysis_tasks()}
            
            # ë°ì´í„° ì¡°íšŒ
            cursor = self.cache_collection.find(query).sort("created_at", -1).limit(limit)
            
            results = []
            for doc in cursor:
                try:
                    # ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
                    analysis_data = doc.get("data", {})

                    has_success = analysis_data.get("success", False)
                    has_result = "result" in analysis_data and analysis_data["result"] is not None

                    # ê¸°ë³¸ ì •ë³´
                    result = {
                        "task_name": doc.get("task_name"),
                        "display_name": self.get_task_display_name(doc.get("task_name", "")),
                        "created_at": doc.get("created_at"),
                        "expire_at": doc.get("expire_at"),
                        "success": has_success and has_result,  # ë‘˜ ë‹¤ ìˆì–´ì•¼ ì„±ê³µ
                        "analysis_result": analysis_data,                # âœ… ì „ì²´ ë°ì´í„° ì €ì¥
                        "raw_data": analysis_data
                    }

                    # ì„±ê³µí•œ ë¶„ì„ì˜ ê²½ìš° ìš”ì•½ ì •ë³´ ì¶”ì¶œ  
                    if result["success"] and "result" in analysis_data:
                        result["summary"] = self._extract_summary(doc.get("task_name"), analysis_data.get("result", {}))
                    else:
                        # ì‹¤íŒ¨í•œ ë¶„ì„ì˜ ê²½ìš° ì‹¤íŒ¨ ì •ë³´ ì¶”ì¶œ
                        result["failure_info"] = self._extract_failure_info(analysis_data)

                    results.append(result)
                    
                except Exception as e:
                    logger.error(f"ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue
            
            return self.sort_by_latest_first(results)
            
        except Exception as e:
            logger.error(f"AI ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []
    
    def _extract_summary(self, task_name: str, analysis_result: Dict) -> Dict:
        """ë¶„ì„ ê²°ê³¼ì—ì„œ ìš”ì•½ ì •ë³´ ì¶”ì¶œ"""
        summary = {
            "confidence": analysis_result.get("confidence", 0),
            "key_points": [],
            "recommendation": "ë¶„ì„ ë¶ˆê°€"
        }
        
        try:
            if task_name == "ai_sentiment_analysis":
                summary.update({
                    "confidence": analysis_result.get("confidence", 0),
                    "sentiment_score": analysis_result.get("market_sentiment_score", 50),
                    "sentiment_state": analysis_result.get("sentiment_state", "ì¤‘ë¦½"),
                    "recommendation": analysis_result.get("investment_recommendation", "ì¤‘ë¦½ì  ì ‘ê·¼")
                })
                
            elif task_name == "ai_technical_analysis":
                summary.update({
                    "confidence": analysis_result.get("confidence", 0),
                    "signal": analysis_result.get("overall_signal", "Hold"),
                    "trend": analysis_result.get("trend_analysis", {}).get("trend_direction", "ì¤‘ë¦½"),
                    "momentum": analysis_result.get("momentum_analysis", {}).get("momentum_direction", "ì¤‘ë¦½"),
                    "recommendation": f"{analysis_result.get('overall_signal', 'Hold')} - {analysis_result.get('trend_analysis', {}).get('trend_direction', 'ì¤‘ë¦½')} ì¶”ì„¸"
                })
                
            elif task_name == "ai_macro_analysis":
                summary.update({
                    "confidence": analysis_result.get("confidence", 0),
                    "macro_score": analysis_result.get("macro_environment_score", 50),
                    "investment_environment": analysis_result.get("investment_environment", "ì¤‘ë¦½"),
                    "recommendation": analysis_result.get("btc_recommendation", "ì‹ ì¤‘í•œ ì ‘ê·¼")
                })
                
            elif task_name == "ai_onchain_analysis":
                summary.update({
                    "confidence": analysis_result.get("confidence", 0),
                    "health_score": analysis_result.get("onchain_health_score", 50),
                    "signal": analysis_result.get("investment_signal", "Hold"),
                    "network_security": analysis_result.get("network_security_analysis", "ì •ìƒ"),
                    "recommendation": analysis_result.get("investment_signal", "ì¤‘ë¦½ì ")
                })
                
            elif task_name == "ai_institutional_analysis":
                summary.update({
                    "confidence": analysis_result.get("confidence", 0),
                    "flow_score": analysis_result.get("institutional_flow_score", 50),
                    "signal": analysis_result.get("investment_signal", "Hold"),
                    "flow_direction": "ë¶„ì‚°" if "Sell" in analysis_result.get("investment_signal", "") else "ì¤‘ë¦½",
                    "recommendation": analysis_result.get("investment_signal", "ê´€ë§")
                })
                
            elif task_name == "final_decision":
                logger.error(f"ğŸ” DEBUG: task_name={task_name}")
                logger.error(f"ğŸ” DEBUG: analysis_result type={type(analysis_result)}")
                logger.error(f"ğŸ” DEBUG: analysis_result keys={list(analysis_result.keys()) if isinstance(analysis_result, dict) else 'NOT_DICT'}")
                logger.error(f"ğŸ” DEBUG: decision_confidence raw={analysis_result.get('decision_confidence', 'NOT_FOUND')}")
                summary.update({
                    "confidence": analysis_result.get("decision_confidence", 0),
                    "decision": analysis_result.get("final_decision", "Hold"),
                    "action": analysis_result.get("recommended_action", {}).get("action_type", "Hold"),
                    "recommendation": analysis_result.get("decision_reasoning", "ë¶„ì„ ì¤‘")[:100] + "...",
                    "needs_human_review" : analysis_result.get("needs_human_review", False),
                    "human_review_reason" : analysis_result.get("human_review_reason", "ë¶„ì„ ì¤‘")[:100] + "..."
                })
            
            # ê³µí†µ í‚¤ í¬ì¸íŠ¸ ì¶”ì¶œ
            if "analysis_summary" in analysis_result:
                summary["key_points"] = [analysis_result["analysis_summary"][:200] + "..."]
                
        except Exception as e:
            logger.error(f"ìš”ì•½ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        return summary
    
    def _extract_failure_info(self, analysis_result: Dict) -> Dict:
        """ì‹¤íŒ¨í•œ ë¶„ì„ ê²°ê³¼ì—ì„œ ì‹¤íŒ¨ ì •ë³´ ì¶”ì¶œ"""
        failure_info = {
            "error_type": "unknown",
            "error_message": "ë¶„ì„ ì‹¤íŒ¨",
            "skip_reason": None,
            "error_count": 0,
            "max_errors": 3,
            "retry_available": True
        }
        
        try:
            if isinstance(analysis_result, dict):
                failure_info.update({
                    "error_type": analysis_result.get("skip_reason", "unknown"),
                    "error_message": analysis_result.get("error", "ë¶„ì„ ì‹¤íŒ¨"),
                    "skip_reason": analysis_result.get("skip_reason"),
                    "error_count": analysis_result.get("error_count", 0),
                    "max_errors": analysis_result.get("max_errors", 3),
                    "retry_available": analysis_result.get("error_count", 0) < analysis_result.get("max_errors", 3)
                })
                
                # ì‹¤íŒ¨ ìœ í˜•ë³„ ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€
                skip_reason = analysis_result.get("skip_reason", "")
                if skip_reason == "insufficient_raw_data":
                    failure_info["user_message"] = "ì›ì‹œ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë¶„ì„ ë¶ˆê°€"
                elif skip_reason == "ai_analysis_failed":
                    failure_info["user_message"] = "AI ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨"
                elif skip_reason == "exception":
                    failure_info["user_message"] = "ë¶„ì„ ì¤‘ ì˜ˆì™¸ ë°œìƒ"
                elif skip_reason == "execution_failed":
                    failure_info["user_message"] = "ë¶„ì„ ì‹¤í–‰ ì‹¤íŒ¨"
                elif skip_reason == "analyzer_disabled":
                    failure_info["user_message"] = "ë¶„ì„ê¸° ë¹„í™œì„±í™” (ì—°ì† ì‹¤íŒ¨)"
                else:
                    failure_info["user_message"] = failure_info["error_message"]
                    
        except Exception as e:
            logger.error(f"ì‹¤íŒ¨ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        return failure_info
    
    def get_analysis_detail(self, task_name: str, created_at: datetime) -> Optional[Dict]:
        """íŠ¹ì • ë¶„ì„ ê²°ê³¼ì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        try:
            # ì •í™•í•œ ì‹œê°„ ë§¤ì¹­ì„ ìœ„í•´ ë²”ìœ„ ê²€ìƒ‰
            time_range = timedelta(seconds=30)
            start_time = created_at - time_range
            end_time = created_at + time_range
            
            doc = self.cache_collection.find_one({
                "task_name": task_name,
                "created_at": {
                    "$gte": start_time,
                    "$lte": end_time
                }
            })
            
            if not doc:
                return None
            
            return {
                "task_name": task_name,
                "display_name": self.get_task_display_name(task_name),
                "created_at": doc.get("created_at"),
                "data": doc.get("data", {}),
                "formatted_data": json.dumps(doc.get("data", {}), indent=2, ensure_ascii=False, default=str)
            }
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None
    
    def get_analysis_statistics(self, hours: int = 24) -> Dict:
        """AI ë¶„ì„ í†µê³„ ì •ë³´"""
        try:
            since_time = datetime.now(timezone.utc) - timedelta(hours=hours)
            
            stats = {
                "total_analyses": 0,
                "success_count": 0,
                "failure_count": 0,
                "by_analyzer": {},
                "success_rate": 0
            }
            
            # ê° ë¶„ì„ê¸°ë³„ í†µê³„
            for task_name in self.get_analysis_tasks():
                cursor = self.cache_collection.find({
                    "task_name": task_name,
                    "created_at": {"$gte": since_time}
                })
                
                task_total = 0
                task_success = 0
                
                for doc in cursor:
                    task_total += 1
                    analysis_data = doc.get("data", {})
                    
                    # ğŸ”§ ìˆ˜ì •: ì˜¬ë°”ë¥¸ success ì²´í¬
                    if analysis_data.get("success", False):  # analysis_result ì œê±°!
                        task_success += 1
                
                stats["by_analyzer"][task_name] = {
                    "display_name": self.get_task_display_name(task_name),
                    "total": task_total,
                    "success": task_success,
                    "failure": task_total - task_success,
                    "success_rate": (task_success / task_total * 100) if task_total > 0 else 0
                }
                
                stats["total_analyses"] += task_total
                stats["success_count"] += task_success
            
            stats["failure_count"] = stats["total_analyses"] - stats["success_count"]
            stats["success_rate"] = (stats["success_count"] / stats["total_analyses"] * 100) if stats["total_analyses"] > 0 else 0
            
            return stats
            
        except Exception as e:
            logger.error(f"ë¶„ì„ í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {"total_analyses": 0, "success_count": 0, "failure_count": 0, "by_analyzer": {}, "success_rate": 0}

# ì „ì—­ ë·°ì–´ ì¸ìŠ¤í„´ìŠ¤
ai_viewer = AIAnalysisViewer()

@router.get("/ai-analysis", response_class=HTMLResponse)
async def ai_analysis_page(
    request: Request,
    analyzer: Optional[str] = Query(None, description="ë¶„ì„ê¸° í•„í„°"),
    hours: int = Query(24, description="ì¡°íšŒ ì‹œê°„ ë²”ìœ„ (ì‹œê°„)"),
    limit: int = Query(50, description="ìµœëŒ€ ê²°ê³¼ ìˆ˜")
):
    """AI ë¶„ì„ ê²°ê³¼ í˜ì´ì§€"""
    try:
        # ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
        analyses = ai_viewer.get_recent_analyses(task_name=analyzer, hours=hours, limit=limit)
        
        # í†µê³„ ì •ë³´ ì¡°íšŒ
        statistics = ai_viewer.get_analysis_statistics(hours=hours)
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë¶„ì„ê¸° ëª©ë¡
        analyzers = [
            {"value": task, "name": ai_viewer.get_task_display_name(task)}
            for task in ai_viewer.get_analysis_tasks()
        ]
        
        return templates.TemplateResponse(
            "ai_analysis.html",
            {
                "request": request,
                "analyses": analyses,
                "statistics": statistics,
                "analyzers": analyzers,
                "current_analyzer": analyzer,
                "hours": hours,
                "limit": limit,
                "total_results": len(analyses)
            }
        )
        
    except Exception as e:
        logger.error(f"AI ë¶„ì„ í˜ì´ì§€ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í˜ì´ì§€ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")

@router.get("/api/ai-analysis")
async def get_ai_analysis_api(
    analyzer: Optional[str] = Query(None),
    hours: int = Query(24),
    limit: int = Query(50)
):
    """AI ë¶„ì„ ê²°ê³¼ API"""
    try:
        analyses = ai_viewer.get_recent_analyses(task_name=analyzer, hours=hours, limit=limit)
        statistics = ai_viewer.get_analysis_statistics(hours=hours)
        
        return {
            "success": True,
            "data": {
                "analyses": analyses,
                "statistics": statistics,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        }
        
    except Exception as e:
        logger.error(f"AI ë¶„ì„ API ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "error": str(e),
            "timestamp": datetime.now(timezone.utc).isoformat()
        }

@router.get("/api/ai-status-quick")
async def get_ai_status_quick():
    """AI ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ë¹ ë¥´ê²Œ í™•ì¸í•˜ëŠ” API (AI API í…ŒìŠ¤íŠ¸ ì œì™¸)"""
    try:
        # AI API í…ŒìŠ¤íŠ¸ ì—†ì´ ê¸°ë³¸ ìƒíƒœë§Œ ì¡°íšŒ
        ai_data_status = get_data_status()
        ai_recovery_status = get_recovery_status()
        ai_api_status = get_ai_api_status_summary()
        
        return {
            "success": True,
            "api_test_result": None,  # ë¹ ë¥¸ ì¡°íšŒì—ì„œëŠ” í…ŒìŠ¤íŠ¸ ì•ˆí•¨
            "ai_data_status": ai_data_status,
            "ai_recovery_status": ai_recovery_status,
            "ai_api_status": ai_api_status,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "note": "ë¹ ë¥¸ ì¡°íšŒ ëª¨ë“œ - AI API í…ŒìŠ¤íŠ¸ ì œì™¸"
        }
        
    except Exception as e:
        logger.error(f"AI ìƒíƒœ ë¹ ë¥¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "error": str(e),
            "ai_api_status": {"is_working": False, "status_text": f"ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}"},
            "timestamp": datetime.now(timezone.utc).isoformat()
        }

@router.get("/ai-analysis/detail", response_class=HTMLResponse)
async def ai_analysis_detail(
    request: Request,
    task_name: str = Query(..., description="ë¶„ì„ ì‘ì—…ëª…"),
    timestamp: str = Query(..., description="ë¶„ì„ ì‹œê° (ISO í˜•ì‹)")
):
    """AI ë¶„ì„ ìƒì„¸ ê²°ê³¼ í˜ì´ì§€"""
    try:
        # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹±
        created_at = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
        
        # ìƒì„¸ ì •ë³´ ì¡°íšŒ
        detail = ai_viewer.get_analysis_detail(task_name, created_at)
        
        if not detail:
            raise HTTPException(status_code=404, detail="ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return templates.TemplateResponse(
            "ai_analysis_detail.html",
            {
                "request": request,
                "detail": detail
            }
        )
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"ì˜ëª»ëœ íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹: {str(e)}")
    except Exception as e:
        logger.error(f"AI ë¶„ì„ ìƒì„¸ í˜ì´ì§€ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í˜ì´ì§€ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
